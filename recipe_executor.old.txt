#!/usr/bin/env python3
"""
Enhanced Recipe Executor - A robust tool for executing LLM "recipes" using pydantic-ai.

This implementation emphasizes code-driven execution, validation, and error handling
to maximize reliability and predictability when working with LLMs.
"""

import os
import re
import glob
import json
import yaml
import logging
import time
from enum import Enum
from pathlib import Path
from typing import (
    List,
    Dict,
    Any,
    Optional,
    Tuple,
    Literal,
    Type,
    cast,
    Protocol,
    runtime_checkable,
    TypeVar,
)
import asyncio
import string
from datetime import datetime
import traceback
import hashlib
import concurrent.futures

from pydantic import (
    BaseModel,
    Field,
    ValidationError,
    create_model,
    model_validator,
)
from pydantic_ai import Agent
from pydantic_ai.messages import ModelMessage

try:
    import pydantic_yaml

    YAML_SUPPORT = True
except ImportError:
    YAML_SUPPORT = False

# ----------------- Logging Configuration -----------------

# Configure logging
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger("recipe-executor")

# Create a file handler for persistent logs
os.makedirs("logs", exist_ok=True)
file_handler = logging.FileHandler(
    f"logs/recipe-executor-{datetime.now().strftime('%Y%m%d-%H%M%S')}.log"
)
file_handler.setLevel(logging.DEBUG)
file_formatter = logging.Formatter(
    "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
file_handler.setFormatter(file_formatter)
logger.addHandler(file_handler)

# ----------------- Execution State Management -----------------


class ExecutionStatus(str, Enum):
    """Status of the recipe execution."""

    NOT_STARTED = "not_started"
    PLANNING = "planning"
    EXECUTING = "executing"
    PAUSED = "paused"
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"


class StepStatus(str, Enum):
    """Status of a step execution."""

    NOT_STARTED = "not_started"
    IN_PROGRESS = "in_progress"
    COMPLETED = "completed"
    FAILED = "failed"
    SKIPPED = "skipped"


class ValidationLevel(str, Enum):
    """Levels of validation strictness."""

    MINIMAL = "minimal"  # Basic type checking
    STANDARD = "standard"  # Schema validation
    STRICT = "strict"  # Comprehensive validation with business rules


class InteractionMode(str, Enum):
    """How the executor interacts with users."""

    NONE = "none"  # No interaction, fails on error
    CRITICAL = "critical"  # Only interact on critical errors
    REGULAR = "regular"  # Interact at key decision points
    VERBOSE = "verbose"  # Interact frequently for guidance


# ----------------- Foundation Models -----------------


class StepType(str, Enum):
    """Types of recipe steps that can be executed."""

    LLM_GENERATE = "llm_generate"
    FILE_READ = "file_read"
    FILE_WRITE = "file_write"
    TEMPLATE_SUBSTITUTE = "template_substitute"
    PARALLEL = "parallel"
    CONDITIONAL = "conditional"
    JSON_PROCESS = "json_process"
    PYTHON_EXECUTE = "python_execute"
    CHAIN = "chain"
    VALIDATOR = "validator"
    WAIT_FOR_INPUT = "wait_for_input"
    API_CALL = "api_call"


class OutputFormat(str, Enum):
    """Output formats that can be used for LLM responses."""

    TEXT = "text"
    JSON = "json"
    STRUCTURED = "structured"
    FILES = "files"


class VariableScope(str, Enum):
    """Scope for variables in the recipe."""

    GLOBAL = "global"  # Available throughout the recipe
    STEP = "step"  # Only available within the step
    CHAIN = "chain"  # Available within a chain of steps


class RecipeMetadata(BaseModel):
    """Metadata about a recipe."""

    name: str = Field(description="Name of the recipe")
    description: Optional[str] = Field(
        description="Description of what the recipe does", default=None
    )
    author: Optional[str] = Field(description="Author of the recipe", default=None)
    version: Optional[str] = Field(description="Version of the recipe", default=None)
    created: Optional[datetime] = Field(
        description="Creation date of the recipe", default=None
    )
    tags: Optional[List[str]] = Field(
        description="Tags associated with the recipe", default=None
    )
    timeout: Optional[int] = Field(
        description="Global timeout in seconds for the recipe execution", default=None
    )


# ----------------- Step Configuration Models -----------------


class ModelConfig(BaseModel):
    """Configuration for an LLM model."""

    provider: Literal["anthropic", "openai", "google", "mistral", "ollama", "groq"] = (
        "anthropic"
    )
    model_name: str = "claude-3-7-sonnet-20250219"
    temperature: float = 0.1
    max_tokens: Optional[int] = None
    system_prompt: Optional[str] = None


class FileInputConfig(BaseModel):
    """Configuration for file input."""

    path: str = Field(description="Path to the file to read")
    pattern: Optional[str] = Field(
        description="Glob pattern for multiple files", default=None
    )
    encoding: str = Field(
        description="Encoding to use when reading the file", default="utf-8"
    )
    as_variable: str = Field(
        description="Name of the variable to store the file content in"
    )


class FileOutputConfig(BaseModel):
    """Configuration for file output."""

    path: str = Field(description="Path to write the file to")
    content_variable: str = Field(
        description="Name of the variable containing the content to write"
    )
    encoding: str = Field(
        description="Encoding to use when writing the file", default="utf-8"
    )
    mode: Literal["w", "a"] = Field(
        description="Write mode - 'w' for write, 'a' for append", default="w"
    )
    mkdir: bool = Field(
        description="Whether to create directories if they don't exist", default=True
    )


class LLMGenerateConfig(BaseModel):
    """Configuration for LLM generation."""

    prompt: str = Field(description="Prompt to send to the LLM")
    model: Optional[str] = Field(
        description="Model ID to use for this generation", default=None
    )
    output_format: OutputFormat = Field(
        description="Format of the output", default=OutputFormat.TEXT
    )
    output_variable: str = Field(
        description="Name of the variable to store the output in"
    )
    temperature: Optional[float] = Field(
        description="Temperature for generation", default=None
    )
    include_history: bool = Field(
        description="Whether to include message history from previous steps",
        default=False,
    )
    history_variable: Optional[str] = Field(
        description="Variable containing history messages to include", default=None
    )
    retry_prompt: Optional[str] = Field(
        description="Prompt to use for retry attempts", default=None
    )
    structured_schema: Optional[Dict[str, Any]] = Field(
        description="Schema for structured output", default=None
    )
    structured_schema_file: Optional[str] = Field(
        description="Path to file containing schema for structured output", default=None
    )
    validation_criteria: Optional[Dict[str, Any]] = Field(
        description="Criteria for validating the output", default=None
    )
    timeout: Optional[int] = Field(
        description="Timeout in seconds for this generation", default=None
    )


class TemplateSubstituteConfig(BaseModel):
    """Configuration for template substitution."""

    template: str = Field(description="Template to substitute variables into")
    template_file: Optional[str] = Field(
        description="Path to file containing the template", default=None
    )
    variables: Dict[str, str] = Field(
        description="Variables to substitute into the template", default_factory=dict
    )
    output_variable: str = Field(
        description="Name of the variable to store the result in"
    )


class JsonProcessConfig(BaseModel):
    """Configuration for JSON processing."""

    input_variable: str = Field(
        description="Name of the variable containing the JSON to process"
    )
    operations: List[Dict[str, Any]] = Field(
        description="Operations to perform on the JSON"
    )
    output_variable: str = Field(
        description="Name of the variable to store the result in"
    )
    validation_schema: Optional[Dict[str, Any]] = Field(
        description="JSON schema for validating the result", default=None
    )


class PythonExecuteConfig(BaseModel):
    """Configuration for executing Python code."""

    code: str = Field(description="Python code to execute")
    code_file: Optional[str] = Field(
        description="Path to file containing Python code", default=None
    )
    input_variables: Dict[str, str] = Field(
        description="Variables to pass to the code", default_factory=dict
    )
    output_variable: str = Field(
        description="Name of the variable to store the result in"
    )
    timeout: Optional[int] = Field(
        description="Timeout in seconds for code execution", default=30
    )
    validation_code: Optional[str] = Field(
        description="Python code to validate the output", default=None
    )
    memory_limit_mb: Optional[int] = Field(
        description="Memory limit in MB for code execution", default=None
    )
    allowed_imports: Optional[List[str]] = Field(
        description="List of modules allowed to be imported", default=None
    )


class ConditionalConfig(BaseModel):
    """Configuration for conditional execution."""

    condition: str = Field(description="Condition to evaluate")
    true_step: Dict[str, Any] = Field(
        description="Step to execute if condition is true"
    )
    false_step: Optional[Dict[str, Any]] = Field(
        description="Step to execute if condition is false", default=None
    )


class ChainConfig(BaseModel):
    """Configuration for chaining steps."""

    steps: List[Dict[str, Any]] = Field(
        description="List of steps to execute in sequence"
    )
    output_variable: Optional[str] = Field(
        description="Name of the variable to store the final result in", default=None
    )
    shared_variables: Optional[List[str]] = Field(
        description="List of variables to share within the chain", default=None
    )
    continue_on_step_failure: bool = Field(
        description="Whether to continue if a step fails", default=False
    )


class ParallelConfig(BaseModel):
    """Configuration for parallel execution."""

    steps: List[Dict[str, Any]] = Field(
        description="List of steps to execute in parallel"
    )
    output_variable: Optional[str] = Field(
        description="Name of the variable to store all results in", default=None
    )
    max_workers: Optional[int] = Field(
        description="Maximum number of worker threads", default=None
    )
    timeout: Optional[int] = Field(
        description="Timeout in seconds for all parallel steps", default=None
    )


class ValidatorConfig(BaseModel):
    """Configuration for validation steps."""

    target_variable: str = Field(description="Name of the variable to validate")
    validation_type: Literal["schema", "code", "llm"] = Field(
        description="Type of validation to perform"
    )
    schema: Optional[Dict[str, Any]] = Field(
        description="JSON schema for validation", default=None
    )
    code: Optional[str] = Field(description="Python code for validation", default=None)
    llm_prompt: Optional[str] = Field(
        description="Prompt for LLM validation", default=None
    )
    output_variable: str = Field(
        description="Name of the variable to store validation result in"
    )
    error_message: Optional[str] = Field(
        description="Custom error message for validation failures", default=None
    )


class WaitForInputConfig(BaseModel):
    """Configuration for waiting for user input."""

    prompt: str = Field(description="Prompt to show to the user")
    output_variable: str = Field(
        description="Name of the variable to store user input in"
    )
    default_value: Optional[Any] = Field(
        description="Default value if no input is provided", default=None
    )
    timeout: Optional[int] = Field(
        description="Timeout in seconds for waiting for input", default=None
    )
    options: Optional[List[str]] = Field(
        description="List of options for the user to choose from", default=None
    )


class ApiCallConfig(BaseModel):
    """Configuration for making API calls."""

    url: str = Field(description="URL to call")
    method: Literal["GET", "POST", "PUT", "DELETE", "PATCH"] = Field(
        description="HTTP method to use", default="GET"
    )
    headers: Optional[Dict[str, str]] = Field(description="HTTP headers", default=None)
    data_variable: Optional[str] = Field(
        description="Name of the variable containing the data to send", default=None
    )
    auth_variable: Optional[str] = Field(
        description="Name of the variable containing auth credentials", default=None
    )
    output_variable: str = Field(
        description="Name of the variable to store the response in"
    )
    timeout: Optional[int] = Field(
        description="Timeout in seconds for the API call", default=30
    )
    retry_count: int = Field(
        description="Number of retries for failed requests", default=3
    )
    retry_delay: int = Field(description="Delay in seconds between retries", default=1)


class RecipeStep(BaseModel):
    """A step in a recipe."""

    id: str = Field(description="Unique identifier for the step")
    name: Optional[str] = Field(
        description="Human-readable name for the step", default=None
    )
    description: Optional[str] = Field(
        description="Description of what the step does", default=None
    )
    type: StepType = Field(description="Type of step to execute")

    # Step-specific configurations
    llm_generate: Optional[LLMGenerateConfig] = Field(
        description="Configuration for LLM generation", default=None
    )
    file_read: Optional[FileInputConfig] = Field(
        description="Configuration for file reading", default=None
    )
    file_write: Optional[FileOutputConfig] = Field(
        description="Configuration for file writing", default=None
    )
    template_substitute: Optional[TemplateSubstituteConfig] = Field(
        description="Configuration for template substitution", default=None
    )
    json_process: Optional[JsonProcessConfig] = Field(
        description="Configuration for JSON processing", default=None
    )
    python_execute: Optional[PythonExecuteConfig] = Field(
        description="Configuration for Python execution", default=None
    )
    conditional: Optional[ConditionalConfig] = Field(
        description="Configuration for conditional execution", default=None
    )
    chain: Optional[ChainConfig] = Field(
        description="Configuration for chaining steps", default=None
    )
    parallel: Optional[ParallelConfig] = Field(
        description="Configuration for parallel execution", default=None
    )
    validator: Optional[ValidatorConfig] = Field(
        description="Configuration for validation", default=None
    )
    wait_for_input: Optional[WaitForInputConfig] = Field(
        description="Configuration for waiting for user input", default=None
    )
    api_call: Optional[ApiCallConfig] = Field(
        description="Configuration for making API calls", default=None
    )

    # Execution control
    condition: Optional[str] = Field(
        description="Condition to determine if this step should run", default=None
    )
    continue_on_error: bool = Field(
        description="Whether to continue execution if this step fails", default=False
    )
    retry_count: int = Field(
        description="Number of times to retry the step if it fails", default=0
    )
    retry_delay: int = Field(description="Delay in seconds between retries", default=1)
    timeout: Optional[int] = Field(
        description="Timeout in seconds for this step", default=None
    )
    depends_on: Optional[List[str]] = Field(
        description="IDs of steps that must complete before this step", default=None
    )
    critical: bool = Field(
        description="Whether this step is critical for the recipe", default=False
    )
    validation_level: ValidationLevel = Field(
        description="Level of validation to apply", default=ValidationLevel.STANDARD
    )

    # For validation
    @model_validator(mode="after")
    def validate_step_config(self) -> "RecipeStep":
        """Validate that the step has the correct configuration for its type."""
        if self.type == StepType.LLM_GENERATE and not self.llm_generate:
            raise ValueError(
                f"Step {self.id} is of type LLM_GENERATE but has no llm_generate configuration"
            )
        if self.type == StepType.FILE_READ and not self.file_read:
            raise ValueError(
                f"Step {self.id} is of type FILE_READ but has no file_read configuration"
            )
        if self.type == StepType.FILE_WRITE and not self.file_write:
            raise ValueError(
                f"Step {self.id} is of type FILE_WRITE but has no file_write configuration"
            )
        if self.type == StepType.TEMPLATE_SUBSTITUTE and not self.template_substitute:
            raise ValueError(
                f"Step {self.id} is of type TEMPLATE_SUBSTITUTE but has no template_substitute configuration"
            )
        if self.type == StepType.JSON_PROCESS and not self.json_process:
            raise ValueError(
                f"Step {self.id} is of type JSON_PROCESS but has no json_process configuration"
            )
        if self.type == StepType.PYTHON_EXECUTE and not self.python_execute:
            raise ValueError(
                f"Step {self.id} is of type PYTHON_EXECUTE but has no python_execute configuration"
            )
        if self.type == StepType.CONDITIONAL and not self.conditional:
            raise ValueError(
                f"Step {self.id} is of type CONDITIONAL but has no conditional configuration"
            )
        if self.type == StepType.CHAIN and not self.chain:
            raise ValueError(
                f"Step {self.id} is of type CHAIN but has no chain configuration"
            )
        if self.type == StepType.PARALLEL and not self.parallel:
            raise ValueError(
                f"Step {self.id} is of type PARALLEL but has no parallel configuration"
            )
        if self.type == StepType.VALIDATOR and not self.validator:
            raise ValueError(
                f"Step {self.id} is of type VALIDATOR but has no validator configuration"
            )
        if self.type == StepType.WAIT_FOR_INPUT and not self.wait_for_input:
            raise ValueError(
                f"Step {self.id} is of type WAIT_FOR_INPUT but has no wait_for_input configuration"
            )
        if self.type == StepType.API_CALL and not self.api_call:
            raise ValueError(
                f"Step {self.id} is of type API_CALL but has no api_call configuration"
            )
        return self


class Recipe(BaseModel):
    """A complete recipe for the LLM to execute."""

    metadata: RecipeMetadata = Field(description="Metadata about the recipe")
    defaults: Optional[Dict[str, Any]] = Field(
        description="Default values to use throughout the recipe", default=None
    )
    model: Optional[ModelConfig] = Field(
        description="Global model configuration for the recipe", default=None
    )
    variables: Dict[str, Any] = Field(
        description="Initial variables for the recipe", default_factory=dict
    )
    steps: List[RecipeStep] = Field(description="Steps to execute in the recipe")
    validation_level: ValidationLevel = Field(
        description="Default validation level for all steps",
        default=ValidationLevel.STANDARD,
    )
    interaction_mode: InteractionMode = Field(
        description="How the executor interacts with users",
        default=InteractionMode.CRITICAL,
    )
    max_retries: int = Field(description="Default maximum retries for steps", default=3)
    timeout: Optional[int] = Field(
        description="Overall timeout for the entire recipe in seconds", default=None
    )


# ----------------- Structured Output Models -----------------


class FileOutput(BaseModel):
    """Represents a file to be written to disk."""

    path: str = Field(description="The path to write the file to")
    content: str = Field(description="The content to write to the file")
    is_new: bool = Field(
        description="Whether this is a new file or a replacement for an existing file"
    )


class FilesGenerationResult(BaseModel):
    """Result of a file generation operation."""

    files: List[FileOutput] = Field(description="Files to write to disk")
    completed: bool = Field(
        description="Whether the generation was completed successfully"
    )
    message: Optional[str] = Field(
        description="Optional message about the generation", default=None
    )


class ValidationIssue(BaseModel):
    """Represents an issue found during validation."""

    message: str = Field(description="Description of the issue")
    severity: Literal["error", "warning", "info"] = Field(
        description="Severity of the issue"
    )
    path: Optional[str] = Field(
        description="Path to the element with the issue", default=None
    )
    context: Optional[Dict[str, Any]] = Field(
        description="Additional context about the issue", default=None
    )


class ValidationResult(BaseModel):
    """Result of a validation operation."""

    valid: bool = Field(description="Whether the validation passed")
    issues: List[ValidationIssue] = Field(
        description="Issues found during validation", default_factory=list
    )
    metadata: Dict[str, Any] = Field(
        description="Additional metadata about the validation", default_factory=dict
    )


class StepResult(BaseModel):
    """Result of a step execution."""

    step_id: str = Field(description="ID of the step")
    status: StepStatus = Field(description="Status of the step execution")
    result: Any = Field(description="Result of the step execution", default=None)
    error: Optional[str] = Field(
        description="Error message if the step failed", default=None
    )
    started_at: datetime = Field(description="When the step started")
    completed_at: Optional[datetime] = Field(
        description="When the step completed", default=None
    )
    duration_seconds: Optional[float] = Field(
        description="Duration of the step execution in seconds", default=None
    )
    validation_result: Optional[ValidationResult] = Field(
        description="Result of validation", default=None
    )
    metadata: Dict[str, Any] = Field(
        description="Additional metadata about the step execution", default_factory=dict
    )


class RecipeResult(BaseModel):
    """Result of a recipe execution."""

    recipe_name: str = Field(description="Name of the recipe")
    status: ExecutionStatus = Field(description="Status of the recipe execution")
    started_at: datetime = Field(description="When the recipe started")
    completed_at: Optional[datetime] = Field(
        description="When the recipe completed", default=None
    )
    duration_seconds: Optional[float] = Field(
        description="Duration of the recipe execution in seconds", default=None
    )
    steps: Dict[str, StepResult] = Field(
        description="Results of step executions", default_factory=dict
    )
    variables: Dict[str, Any] = Field(
        description="Final variables after recipe execution", default_factory=dict
    )
    error: Optional[str] = Field(
        description="Error message if the recipe failed", default=None
    )


# ----------------- Event Classes for Progress Tracking -----------------


class ExecutionEvent(BaseModel):
    """Base class for execution events."""

    timestamp: datetime = Field(
        description="When the event occurred", default_factory=datetime.now
    )
    event_type: str = Field(description="Type of event")


class StepStartEvent(ExecutionEvent):
    """Event emitted when a step starts."""

    event_type: str = "step_start"
    step_id: str = Field(description="ID of the step")
    step_name: Optional[str] = Field(description="Name of the step", default=None)
    step_type: StepType = Field(description="Type of the step")


class StepCompleteEvent(ExecutionEvent):
    """Event emitted when a step completes."""

    event_type: str = "step_complete"
    step_id: str = Field(description="ID of the step")
    status: StepStatus = Field(description="Status of the step")
    duration_seconds: float = Field(
        description="Duration of the step execution in seconds"
    )


class StepFailedEvent(ExecutionEvent):
    """Event emitted when a step fails."""

    event_type: str = "step_failed"
    step_id: str = Field(description="ID of the step")
    error: str = Field(description="Error message")
    traceback: Optional[str] = Field(description="Error traceback", default=None)


class ValidationEvent(ExecutionEvent):
    """Event emitted during validation."""

    event_type: str = "validation"
    valid: bool = Field(description="Whether validation passed")
    issues_count: int = Field(description="Number of validation issues")


class LLMGenerationEvent(ExecutionEvent):
    """Event emitted during LLM generation."""

    event_type: str = "llm_generation"
    model: str = Field(description="Model used")
    prompt_length: int = Field(description="Length of the prompt in characters")


class UserInteractionEvent(ExecutionEvent):
    """Event emitted when user interaction is required."""

    event_type: str = "user_interaction"
    prompt: str = Field(description="Prompt shown to the user")


class RecipeStartEvent(ExecutionEvent):
    """Event emitted when a recipe starts."""

    event_type: str = "recipe_start"
    recipe_name: str = Field(description="Name of the recipe")


class RecipeCompleteEvent(ExecutionEvent):
    """Event emitted when a recipe completes."""

    event_type: str = "recipe_complete"
    recipe_name: str = Field(description="Name of the recipe")
    status: ExecutionStatus = Field(description="Status of the recipe execution")
    duration_seconds: float = Field(
        description="Duration of the recipe execution in seconds"
    )


# ----------------- Event Listener Interface -----------------


@runtime_checkable
class EventListener(Protocol):
    """Interface for event listeners."""

    def on_event(self, event: ExecutionEvent) -> None:
        """Called when an event occurs."""
        ...


class ConsoleEventListener:
    """Event listener that prints events to the console."""

    def on_event(self, event: ExecutionEvent) -> None:
        """Print the event to the console."""
        if event.event_type == "step_start":
            event = cast(StepStartEvent, event)
            logger.info(
                f"Starting step: {event.step_id} ({event.step_name or event.step_type})"
            )
        elif event.event_type == "step_complete":
            event = cast(StepCompleteEvent, event)
            logger.info(
                f"Completed step: {event.step_id} ({event.status}) in {event.duration_seconds:.2f}s"
            )
        elif event.event_type == "step_failed":
            event = cast(StepFailedEvent, event)
            logger.error(f"Failed step: {event.step_id} - {event.error}")
        elif event.event_type == "validation":
            event = cast(ValidationEvent, event)
            if event.valid:
                logger.info(f"Validation passed with {event.issues_count} issues")
            else:
                logger.warning(f"Validation failed with {event.issues_count} issues")
        elif event.event_type == "llm_generation":
            event = cast(LLMGenerationEvent, event)
            logger.info(
                f"LLM generation with model {event.model} (prompt length: {event.prompt_length})"
            )
        elif event.event_type == "user_interaction":
            event = cast(UserInteractionEvent, event)
            logger.info(f"User interaction required: {event.prompt}")
        elif event.event_type == "recipe_start":
            event = cast(RecipeStartEvent, event)
            logger.info(f"Starting recipe: {event.recipe_name}")
        elif event.event_type == "recipe_complete":
            event = cast(RecipeCompleteEvent, event)
            logger.info(
                f"Completed recipe: {event.recipe_name} ({event.status}) in {event.duration_seconds:.2f}s"
            )


# ----------------- Step Executor Interfaces -----------------


@runtime_checkable
class StepExecutor(Protocol):
    """Interface for step executors."""

    async def execute(self, step: RecipeStep, context: "ExecutionContext") -> Any:
        """Execute a step with the given context."""
        ...

    async def validate_result(
        self, step: RecipeStep, result: Any, context: "ExecutionContext"
    ) -> ValidationResult:
        """Validate the result of a step execution."""
        ...


# ----------------- Dependency Injection and Context -----------------

T = TypeVar("T")


class ExecutionContext:
    """
    Context for recipe execution, containing variables, state, and dependencies.
    Implements a scoped variable system with inheritance and isolation.
    """

    def __init__(
        self,
        variables: Dict[str, Any] = None,
        parent: Optional["ExecutionContext"] = None,
        scope: VariableScope = VariableScope.GLOBAL,
        recipe: Optional[Recipe] = None,
        interaction_mode: InteractionMode = InteractionMode.CRITICAL,
        validation_level: ValidationLevel = ValidationLevel.STANDARD,
    ):
        """Initialize the execution context."""
        self.variables = variables or {}
        self.parent = parent
        self.scope = scope
        self.recipe = recipe
        self._message_history = {}
        self._step_results = {}
        self._current_step = None
        self._event_listeners = []
        self.interaction_mode = interaction_mode
        self.validation_level = validation_level

        # Add the parent's event listeners
        if parent:
            for listener in parent._event_listeners:
                self._event_listeners.append(listener)

    def add_event_listener(self, listener: EventListener) -> None:
        """Add an event listener."""
        self._event_listeners.append(listener)

    def emit_event(self, event: ExecutionEvent) -> None:
        """Emit an event to all listeners."""
        for listener in self._event_listeners:
            try:
                listener.on_event(event)
            except Exception as e:
                logger.error(f"Error in event listener: {e}")

    def get_variable(self, name: str, default: Any = None) -> Any:
        """
        Get a variable from the context or its parents.

        Args:
            name: Name of the variable
            default: Default value if the variable doesn't exist

        Returns:
            Value of the variable or the default
        """
        if name in self.variables:
            return self.variables[name]
        elif self.parent:
            return self.parent.get_variable(name, default)
        else:
            return default

    def set_variable(
        self, name: str, value: Any, scope: Optional[VariableScope] = None
    ) -> None:
        """
        Set a variable in the appropriate scope.

        Args:
            name: Name of the variable
            value: Value to set
            scope: Scope to set the variable in, or None to use the current scope
        """
        if scope == VariableScope.GLOBAL or (
            not scope and self.scope == VariableScope.GLOBAL
        ):
            # Set in the root context
            if self.parent:
                self.parent.set_variable(name, value, VariableScope.GLOBAL)
            else:
                self.variables[name] = value
        else:
            # Set in the current context
            self.variables[name] = value

    def create_child_context(
        self, scope: VariableScope = VariableScope.STEP
    ) -> "ExecutionContext":
        """
        Create a child context with this context as its parent.

        Args:
            scope: Scope for the child context

        Returns:
            A new ExecutionContext with this context as its parent
        """
        return ExecutionContext(
            variables={},
            parent=self,
            scope=scope,
            recipe=self.recipe,
            interaction_mode=self.interaction_mode,
            validation_level=self.validation_level,
        )

    def get_message_history(self, step_id: str) -> List[ModelMessage]:
        """
        Get the message history for a step.

        Args:
            step_id: ID of the step

        Returns:
            List of messages in the history
        """
        if step_id in self._message_history:
            return self._message_history[step_id]
        elif self.parent:
            return self.parent.get_message_history(step_id)
        else:
            return []

    def set_message_history(self, step_id: str, messages: List[ModelMessage]) -> None:
        """
        Set the message history for a step.

        Args:
            step_id: ID of the step
            messages: List of messages to set
        """
        if self.scope == VariableScope.GLOBAL:
            self._message_history[step_id] = messages
        elif self.parent:
            self.parent.set_message_history(step_id, messages)

    def get_step_result(self, step_id: str) -> Optional[StepResult]:
        """
        Get the result of a step.

        Args:
            step_id: ID of the step

        Returns:
            Result of the step or None if not found
        """
        if step_id in self._step_results:
            return self._step_results[step_id]
        elif self.parent:
            return self.parent.get_step_result(step_id)
        else:
            return None

    def set_step_result(self, step_id: str, result: StepResult) -> None:
        """
        Set the result of a step.

        Args:
            step_id: ID of the step
            result: Result to set
        """
        if self.scope == VariableScope.GLOBAL:
            self._step_results[step_id] = result
        elif self.parent:
            self.parent.set_step_result(step_id, result)

    def set_current_step(self, step: Optional[RecipeStep]) -> None:
        """
        Set the current step being executed.

        Args:
            step: Step being executed or None
        """
        self._current_step = step
        if self.parent:
            self.parent.set_current_step(step)

    def get_current_step(self) -> Optional[RecipeStep]:
        """
        Get the current step being executed.

        Returns:
            The current step or None
        """
        if self._current_step:
            return self._current_step
        elif self.parent:
            return self.parent.get_current_step()
        else:
            return None

    def interpolate_variables(self, text: str) -> str:
        """
        Interpolate variables in a string using the template engine.

        Args:
            text: Text to interpolate

        Returns:
            Interpolated text
        """
        if not text:
            return text

        template = string.Template(text)

        # Get all potential variables from the template
        var_pattern = r"\$\{([^}]*)\}|\$([a-zA-Z0-9_]+)"
        var_matches = re.finditer(var_pattern, text)
        var_names = [match.group(1) or match.group(2) for match in var_matches]

        # Prepare substitutions
        substitutions = {}
        for var_name in var_names:
            # Check for nested references
            if "." in var_name:
                parts = var_name.split(".")
                obj = self.get_variable(parts[0])
                value = obj
                for part in parts[1:]:
                    if isinstance(value, dict) and part in value:
                        value = value[part]
                    elif hasattr(value, part):
                        value = getattr(value, part)
                    else:
                        value = None
                        break
            else:
                # Direct variable reference
                value = self.get_variable(var_name)

            # Convert to string if possible
            if value is not None:
                if isinstance(value, (dict, list)):
                    substitutions[var_name] = json.dumps(value)
                else:
                    substitutions[var_name] = str(value)
            else:
                substitutions[var_name] = ""

        return template.safe_substitute(substitutions)

    def evaluate_condition(self, condition: str) -> bool:
        """
        Evaluate a condition with access to the variables.

        Args:
            condition: Condition to evaluate

        Returns:
            Result of the condition evaluation
        """
        if not condition:
            return True

        # Interpolate variables first
        condition = self.interpolate_variables(condition)

        # Create a safe evaluation context
        eval_globals = {
            "len": len,
            "str": str,
            "int": int,
            "float": float,
            "bool": bool,
            "list": list,
            "dict": dict,
            "set": set,
            "sum": sum,
            "min": min,
            "max": max,
            "all": all,
            "any": any,
            "enumerate": enumerate,
            "zip": zip,
            "datetime": datetime,
            "re": re,
            "variables": {k: self.get_variable(k) for k in self.variables},
        }

        try:
            return bool(eval(condition, eval_globals, {}))
        except Exception as e:
            logger.error(f"Error evaluating condition '{condition}': {e}")
            return False


# ----------------- Concrete Step Executors -----------------


class LLMGenerateExecutor:
    """Executor for LLM generation steps."""

    def __init__(self, cache_dir: Optional[str] = None):
        """Initialize the executor."""
        self.agents_cache = {}
        self.cache_dir = cache_dir
        if cache_dir:
            os.makedirs(cache_dir, exist_ok=True)

    def _get_agent(
        self,
        model_provider: str,
        model_name: str,
        result_type: Type,
        system_prompt: Optional[str] = None,
        temp: Optional[float] = None,
    ) -> Agent:
        """Get an agent from the cache or create a new one."""
        cache_key = f"{model_provider}:{model_name}:{result_type.__name__}:{system_prompt}:{temp}"
        if cache_key not in self.agents_cache:
            model_id = (
                f"{model_provider}:{model_name}"
                if model_provider != "openai"
                else model_name
            )
            agent = Agent(
                model_id,
                result_type=result_type,
                model_settings={
                    "temperature": temp if temp is not None else 0.1,
                },
                system_prompt=system_prompt,
            )
            self.agents_cache[cache_key] = agent
        return self.agents_cache[cache_key]

    async def _create_dynamic_model(
        self, schema: Dict[str, Any], context: ExecutionContext
    ) -> Type[BaseModel]:
        """
        Create a Pydantic model dynamically from a schema.

        Args:
            schema: Schema definition for the model
            context: Execution context

        Returns:
            Dynamically created Pydantic model
        """
        # Extract the fields from the schema
        fields = {}
        for field_name, field_def in schema.get("properties", {}).items():
            field_type = field_def.get("type")
            description = field_def.get("description", "")

            if field_type == "string":
                fields[field_name] = (str, Field(description=description))
            elif field_type == "integer":
                fields[field_name] = (int, Field(description=description))
            elif field_type == "number":
                fields[field_name] = (float, Field(description=description))
            elif field_type == "boolean":
                fields[field_name] = (bool, Field(description=description))
            elif field_type == "array":
                items = field_def.get("items", {})
                item_type = items.get("type", "string")
                if item_type == "string":
                    fields[field_name] = (List[str], Field(description=description))
                elif item_type == "integer":
                    fields[field_name] = (List[int], Field(description=description))
                elif item_type == "number":
                    fields[field_name] = (List[float], Field(description=description))
                elif item_type == "boolean":
                    fields[field_name] = (List[bool], Field(description=description))
                else:
                    fields[field_name] = (List[Any], Field(description=description))
            elif field_type == "object":
                # For now, treat nested objects as dictionaries
                fields[field_name] = (Dict[str, Any], Field(description=description))
            else:
                # Default to Any for unknown types
                fields[field_name] = (Any, Field(description=description))

        # Create the model with the extracted fields
        model_name = schema.get("title", "DynamicModel")
        model = create_model(model_name, **fields)
        return model

    async def execute(self, step: RecipeStep, context: ExecutionContext) -> Any:
        """
        Execute an LLM generation step.

        Args:
            step: Step to execute
            context: Execution context

        Returns:
            Generated content from the LLM
        """
        if not step.llm_generate:
            raise ValueError(f"Missing llm_generate configuration for step {step.id}")

        config = step.llm_generate
        prompt = context.interpolate_variables(config.prompt)

        # Emit LLM generation event
        event = LLMGenerationEvent(
            model=config.model or "default", prompt_length=len(prompt)
        )
        context.emit_event(event)

        # Determine which model to use
        model_provider = "anthropic"
        model_name = config.model

        if context.recipe and context.recipe.model:
            model_provider = context.recipe.model.provider
            if not model_name:
                model_name = context.recipe.model.model_name

        if not model_name:
            model_name = "claude-3-7-sonnet-20250219"

        # Get the temperature
        temp = config.temperature
        if temp is None and context.recipe and context.recipe.model:
            temp = context.recipe.model.temperature

        # Get the system prompt
        system_prompt = None
        if (
            context.recipe
            and context.recipe.model
            and context.recipe.model.system_prompt
        ):
            system_prompt = context.interpolate_variables(
                context.recipe.model.system_prompt
            )

        # Cache key for result type and prompt
        cache_key = None
        if self.cache_dir:
            h = hashlib.md5()
            h.update(prompt.encode("utf-8"))
            if system_prompt:
                h.update(system_prompt.encode("utf-8"))
            h.update(str(config.output_format).encode("utf-8"))
            if config.structured_schema:
                h.update(json.dumps(config.structured_schema).encode("utf-8"))
            cache_key = h.hexdigest()
            cache_file = os.path.join(self.cache_dir, f"{cache_key}.json")

            # Check if we have a cached result
            if os.path.exists(cache_file):
                try:
                    with open(cache_file, "r") as f:
                        cached_data = json.load(f)
                    logger.info(f"Using cached result for step {step.id}")
                    return cached_data.get("result")
                except Exception as e:
                    logger.warning(f"Failed to load cached result: {e}")

        # Prepare message history if needed
        message_history = None
        if config.include_history:
            message_history = context.get_message_history(step.id)
        elif config.history_variable and config.history_variable in context.variables:
            history_var = context.get_variable(config.history_variable)
            if isinstance(history_var, list) and all(
                isinstance(msg, ModelMessage) for msg in history_var
            ):
                message_history = history_var

        # Handle structured output
        result_type: Type = str

        if config.output_format == OutputFormat.JSON:
            result_type = Dict[str, Any]
        elif config.output_format == OutputFormat.FILES:
            result_type = FilesGenerationResult
        elif config.output_format == OutputFormat.STRUCTURED:
            # Create a dynamic model from the schema
            schema = None

            if config.structured_schema:
                schema = config.structured_schema
            elif config.structured_schema_file:
                schema_file = context.interpolate_variables(
                    config.structured_schema_file
                )
                try:
                    with open(schema_file, "r") as f:
                        if schema_file.endswith(".json"):
                            schema = json.load(f)
                        elif schema_file.endswith((".yaml", ".yml")) and YAML_SUPPORT:
                            schema = yaml.safe_load(f)
                        else:
                            raise ValueError(
                                f"Unsupported schema file format: {schema_file}"
                            )
                except Exception as e:
                    logger.error(f"Error loading schema file {schema_file}: {e}")
                    raise

            if schema:
                result_type = await self._create_dynamic_model(schema, context)
            else:
                # Default to Dict if no schema provided
                result_type = Dict[str, Any]

        # Set up timeout handling
        timeout = config.timeout
        if timeout is None and step.timeout:
            timeout = step.timeout
        if timeout is None and context.recipe and context.recipe.timeout:
            timeout = context.recipe.timeout

        # Get the agent
        agent = self._get_agent(
            model_provider=model_provider,
            model_name=model_name,
            result_type=result_type,
            system_prompt=system_prompt,
            temp=temp,
        )

        # Run the agent with timeout if specified
        if timeout:
            try:
                result = await asyncio.wait_for(
                    agent.run(
                        prompt,
                        message_history=message_history,
                    ),
                    timeout=timeout,
                )
            except asyncio.TimeoutError:
                logger.error(
                    f"LLM generation timed out after {timeout}s for step {step.id}"
                )
                raise TimeoutError(f"LLM generation timed out after {timeout}s")
        else:
            result = await agent.run(
                prompt,
                message_history=message_history,
            )

        # Store the message history
        context.set_message_history(step.id, result.new_messages())

        # Store the result in the cache if enabled
        if cache_key and self.cache_dir:
            try:
                with open(os.path.join(self.cache_dir, f"{cache_key}.json"), "w") as f:
                    json.dump(
                        {
                            "prompt": prompt,
                            "system_prompt": system_prompt,
                            "result": result.data,
                        },
                        f,
                    )
            except Exception as e:
                logger.warning(f"Failed to cache result: {e}")

        return result.data

    async def validate_result(
        self, step: RecipeStep, result: Any, context: ExecutionContext
    ) -> ValidationResult:
        """
        Validate the result of an LLM generation step.

        Args:
            step: Step to validate
            result: Result to validate
            context: Execution context

        Returns:
            Validation result
        """
        if not step.llm_generate:
            return ValidationResult(valid=True, issues=[])

        config = step.llm_generate

        # For structured output, the validation is done by Pydantic
        if (
            config.output_format == OutputFormat.STRUCTURED
            and config.validation_criteria
        ):
            issues = []
            valid = True

            for criterion_name, criterion_config in config.validation_criteria.items():
                criterion_type = criterion_config.get("type", "presence")
                field_path = criterion_config.get("field", "")

                # Get the field value
                field_value = result
                if field_path:
                    for part in field_path.split("."):
                        if isinstance(field_value, dict) and part in field_value:
                            field_value = field_value[part]
                        else:
                            field_value = None
                            break

                # Validate based on criterion type
                if criterion_type == "presence" and field_value is None:
                    issues.append(
                        ValidationIssue(
                            message=f"Field {field_path} is required but missing",
                            severity="error",
                            path=field_path,
                        )
                    )
                    valid = False
                elif criterion_type == "non_empty" and (
                    field_value is None
                    or field_value == ""
                    or field_value == []
                    or field_value == {}
                ):
                    issues.append(
                        ValidationIssue(
                            message=f"Field {field_path} must not be empty",
                            severity="error",
                            path=field_path,
                        )
                    )
                    valid = False
                elif (
                    criterion_type == "min_length"
                    and isinstance(field_value, (str, list))
                    and len(field_value) < criterion_config.get("value", 0)
                ):
                    issues.append(
                        ValidationIssue(
                            message=f"Field {field_path} must have length at least {criterion_config.get('value', 0)}",
                            severity="error",
                            path=field_path,
                        )
                    )
                    valid = False
                elif (
                    criterion_type == "max_length"
                    and isinstance(field_value, (str, list))
                    and len(field_value) > criterion_config.get("value", float("inf"))
                ):
                    issues.append(
                        ValidationIssue(
                            message=f"Field {field_path} must have length at most {criterion_config.get('value', float('inf'))}",
                            severity="error",
                            path=field_path,
                        )
                    )
                    valid = False
                elif criterion_type == "custom" and "condition" in criterion_config:
                    condition = criterion_config["condition"]
                    # Replace field references with actual values
                    condition = condition.replace("field_value", repr(field_value))

                    try:
                        if not eval(condition):
                            issues.append(
                                ValidationIssue(
                                    message=criterion_config.get(
                                        "message",
                                        f"Field {field_path} failed custom validation",
                                    ),
                                    severity="error",
                                    path=field_path,
                                )
                            )
                            valid = False
                    except Exception as e:
                        issues.append(
                            ValidationIssue(
                                message=f"Error evaluating custom condition for {field_path}: {e}",
                                severity="error",
                                path=field_path,
                            )
                        )
                        valid = False

            return ValidationResult(valid=valid, issues=issues)

        # For file generation, check that all files are valid
        if config.output_format == OutputFormat.FILES and isinstance(
            result, FilesGenerationResult
        ):
            issues = []
            valid = True

            if not result.completed:
                issues.append(
                    ValidationIssue(
                        message="File generation was marked as incomplete",
                        severity="error",
                    )
                )
                valid = False

            if not result.files:
                issues.append(
                    ValidationIssue(message="No files were generated", severity="error")
                )
                valid = False

            for i, file in enumerate(result.files):
                if not file.path:
                    issues.append(
                        ValidationIssue(
                            message=f"File {i + 1} has no path",
                            severity="error",
                            path=f"files[{i}].path",
                        )
                    )
                    valid = False

                if not file.content:
                    issues.append(
                        ValidationIssue(
                            message=f"File {i + 1} ({file.path}) has no content",
                            severity="warning",
                            path=f"files[{i}].content",
                        )
                    )

            return ValidationResult(valid=valid, issues=issues)

        # Default validation for text output
        return ValidationResult(valid=True, issues=[])


class FileReadExecutor:
    """Executor for file read steps."""

    async def execute(self, step: RecipeStep, context: ExecutionContext) -> Any:
        """
        Execute a file read step.

        Args:
            step: Step to execute
            context: Execution context

        Returns:
            File content
        """
        if not step.file_read:
            raise ValueError(f"Missing file_read configuration for step {step.id}")

        config = step.file_read
        path = context.interpolate_variables(config.path)

        if config.pattern:
            pattern = context.interpolate_variables(config.pattern)
            file_paths = glob.glob(os.path.join(os.path.dirname(path), pattern))
            if not file_paths:
                logger.warning(f"No files found matching pattern {pattern}")
                return {}

            # Read all matching files
            contents = {}
            for file_path in file_paths:
                try:
                    with open(file_path, "r", encoding=config.encoding) as f:
                        contents[os.path.basename(file_path)] = f.read()
                except Exception as e:
                    logger.error(f"Error reading file {file_path}: {e}")
                    if not step.continue_on_error:
                        raise

            return contents
        else:
            # Read a single file
            try:
                with open(path, "r", encoding=config.encoding) as f:
                    content = f.read()

                return content
            except Exception as e:
                logger.error(f"Error reading file {path}: {e}")
                if not step.continue_on_error:
                    raise
                return None

    async def validate_result(
        self, step: RecipeStep, result: Any, context: ExecutionContext
    ) -> ValidationResult:
        """
        Validate the result of a file read step.

        Args:
            step: Step to validate
            result: Result to validate
            context: Execution context

        Returns:
            Validation result
        """
        if not step.file_read:
            return ValidationResult(valid=True, issues=[])

        config = step.file_read

        # For pattern-based file reading, check that at least one file was found
        if config.pattern and isinstance(result, dict) and not result:
            return ValidationResult(
                valid=False,
                issues=[
                    ValidationIssue(
                        message=f"No files found matching pattern {config.pattern}",
                        severity="error",
                    )
                ],
            )

        # For single file reading, check that the file was read
        if not config.pattern and result is None:
            return ValidationResult(
                valid=False,
                issues=[
                    ValidationIssue(
                        message=f"Failed to read file {config.path}", severity="error"
                    )
                ],
            )

        return ValidationResult(valid=True, issues=[])


class FileWriteExecutor:
    """Executor for file write steps."""

    async def execute(self, step: RecipeStep, context: ExecutionContext) -> bool:
        """
        Execute a file write step.

        Args:
            step: Step to execute
            context: Execution context

        Returns:
            True if the file was written successfully
        """
        if not step.file_write:
            raise ValueError(f"Missing file_write configuration for step {step.id}")

        config = step.file_write
        path = context.interpolate_variables(config.path)

        content_var = context.get_variable(config.content_variable)
        if content_var is None:
            raise ValueError(f"Content variable {config.content_variable} not found")

        content = content_var
        if not isinstance(content, str):
            # Try to convert to string
            if isinstance(content, (dict, list)):
                content = json.dumps(content, indent=2)
            else:
                content = str(content)

        # Create directory if needed
        if config.mkdir:
            os.makedirs(os.path.dirname(path), exist_ok=True)

        try:
            with open(path, config.mode, encoding=config.encoding) as f:
                f.write(content)

            logger.info(f"Wrote file: {path}")
            return True
        except Exception as e:
            logger.error(f"Error writing file {path}: {e}")
            if not step.continue_on_error:
                raise
            return False

    async def validate_result(
        self, step: RecipeStep, result: Any, context: ExecutionContext
    ) -> ValidationResult:
        """
        Validate the result of a file write step.

        Args:
            step: Step to validate
            result: Result to validate
            context: Execution context

        Returns:
            Validation result
        """
        if not step.file_write:
            return ValidationResult(valid=True, issues=[])

        config = step.file_write
        path = context.interpolate_variables(config.path)

        # Check that the file was written
        if not result:
            return ValidationResult(
                valid=False,
                issues=[
                    ValidationIssue(
                        message=f"Failed to write file {path}", severity="error"
                    )
                ],
            )

        # Check that the file exists
        if not os.path.exists(path):
            return ValidationResult(
                valid=False,
                issues=[
                    ValidationIssue(
                        message=f"File {path} does not exist after write operation",
                        severity="error",
                    )
                ],
            )

        return ValidationResult(valid=True, issues=[])


class TemplateSubstituteExecutor:
    """Executor for template substitution steps."""

    async def execute(self, step: RecipeStep, context: ExecutionContext) -> str:
        """
        Execute a template substitution step.

        Args:
            step: Step to execute
            context: Execution context

        Returns:
            Substituted template
        """
        if not step.template_substitute:
            raise ValueError(
                f"Missing template_substitute configuration for step {step.id}"
            )

        config = step.template_substitute

        # Get the template content
        if config.template_file:
            template_file = context.interpolate_variables(config.template_file)
            try:
                with open(template_file, "r") as f:
                    template_content = f.read()
            except Exception as e:
                logger.error(f"Error reading template file {template_file}: {e}")
                if not step.continue_on_error:
                    raise
                return ""
        else:
            template_content = config.template

        # Create a Template object
        template = string.Template(template_content)

        # Get variables to substitute
        variables = {}
        for var_name, var_source in config.variables.items():
            var_source = context.interpolate_variables(var_source)
            var_value = context.get_variable(var_source)
            if var_value is not None:
                variables[var_name] = var_value
            else:
                variables[var_name] = var_source

        # Convert all variables to strings for interpolation
        str_variables = {
            k: str(v) if v is not None else "" for k, v in variables.items()
        }

        # Perform substitution
        result = template.safe_substitute(str_variables)

        return result

    async def validate_result(
        self, step: RecipeStep, result: Any, context: ExecutionContext
    ) -> ValidationResult:
        """
        Validate the result of a template substitution step.

        Args:
            step: Step to validate
            result: Result to validate
            context: Execution context

        Returns:
            Validation result
        """
        if not step.template_substitute:
            return ValidationResult(valid=True, issues=[])

        # Check for unresolved variables
        unresolved_vars = re.findall(r"\$\{([^}]*)\}", result)

        if unresolved_vars:
            return ValidationResult(
                valid=False,
                issues=[
                    ValidationIssue(
                        message=f"Unresolved variable(s) in template: {', '.join(unresolved_vars)}",
                        severity="warning",
                    )
                ],
            )

        return ValidationResult(valid=True, issues=[])


class JsonProcessExecutor:
    """Executor for JSON processing steps."""

    async def execute(
        self, step: RecipeStep, context: ExecutionContext
    ) -> Dict[str, Any]:
        """
        Execute a JSON process step.

        Args:
            step: Step to execute
            context: Execution context

        Returns:
            Processed JSON data
        """
        if not step.json_process:
            raise ValueError(f"Missing json_process configuration for step {step.id}")

        config = step.json_process

        input_var = context.get_variable(config.input_variable)
        if input_var is None:
            raise ValueError(f"Input variable {config.input_variable} not found")

        # If input is a string, try to parse it as JSON
        if isinstance(input_var, str):
            try:
                input_data = json.loads(input_var)
            except json.JSONDecodeError:
                logger.warning(f"Failed to parse input as JSON: {input_var[:100]}...")
                input_data = {"text": input_var}
        else:
            input_data = input_var

        result = input_data

        # Process each operation in sequence
        for op in config.operations:
            op_type = op.get("type")

            if op_type == "extract":
                # Extract a value from the JSON using a path
                path = op.get("path", "")
                default = op.get("default")
                keys = path.split(".")

                value = result
                for key in keys:
                    if isinstance(value, dict) and key in value:
                        value = value[key]
                    elif (
                        isinstance(value, list)
                        and key.isdigit()
                        and int(key) < len(value)
                    ):
                        value = value[int(key)]
                    else:
                        value = default
                        break

                result = value
            elif op_type == "filter":
                # Filter an array of objects based on a condition
                if not isinstance(result, list):
                    logger.warning(
                        f"Filter operation requires a list, got {type(result)}"
                    )
                    continue

                field = op.get("field", "")
                value = op.get("value")
                operator = op.get("operator", "eq")

                filtered = []
                for item in result:
                    if not isinstance(item, dict):
                        continue

                    item_value = item.get(field)

                    if operator == "eq" and item_value == value:
                        filtered.append(item)
                    elif operator == "ne" and item_value != value:
                        filtered.append(item)
                    elif operator == "gt" and item_value > value:
                        filtered.append(item)
                    elif operator == "lt" and item_value < value:
                        filtered.append(item)
                    elif operator == "contains" and value in item_value:
                        filtered.append(item)
                    elif (
                        operator == "startswith"
                        and isinstance(item_value, str)
                        and item_value.startswith(value)
                    ):
                        filtered.append(item)
                    elif (
                        operator == "endswith"
                        and isinstance(item_value, str)
                        and item_value.endswith(value)
                    ):
                        filtered.append(item)
                    elif operator == "in" and item_value in value:
                        filtered.append(item)

                result = filtered
            elif op_type == "map":
                # Map an array of objects to a new array
                if not isinstance(result, list):
                    logger.warning(f"Map operation requires a list, got {type(result)}")
                    continue

                template = op.get("template", {})

                mapped = []
                for item in result:
                    if not isinstance(item, dict):
                        continue

                    new_item = {}
                    for new_key, source_path in template.items():
                        keys = source_path.split(".")
                        value = item
                        for key in keys:
                            if isinstance(value, dict) and key in value:
                                value = value[key]
                            else:
                                value = None
                                break

                        new_item[new_key] = value

                    mapped.append(new_item)

                result = mapped
            elif op_type == "merge":
                # Merge multiple objects
                other_var = op.get("with")
                if other_var in context.variables:
                    other_data = context.get_variable(other_var)
                    if isinstance(other_data, dict) and isinstance(result, dict):
                        result = {**result, **other_data}
                    elif isinstance(other_data, list) and isinstance(result, list):
                        result.extend(other_data)
            elif op_type == "sort":
                # Sort an array
                if not isinstance(result, list):
                    logger.warning(
                        f"Sort operation requires a list, got {type(result)}"
                    )
                    continue

                field = op.get("field")
                reverse = op.get("reverse", False)

                if field:
                    # Sort by field
                    result = sorted(
                        result,
                        key=lambda x: x.get(field) if isinstance(x, dict) else x,
                        reverse=reverse,
                    )
                else:
                    # Sort directly
                    result = sorted(result, reverse=reverse)
            elif op_type == "group":
                # Group by field
                if not isinstance(result, list):
                    logger.warning(
                        f"Group operation requires a list, got {type(result)}"
                    )
                    continue

                field = op.get("field")
                if not field:
                    logger.warning("Group operation requires a field")
                    continue

                grouped = {}
                for item in result:
                    if not isinstance(item, dict):
                        continue

                    key = item.get(field)
                    if key not in grouped:
                        grouped[key] = []

                    grouped[key].append(item)

                result = grouped
            elif op_type == "aggregate":
                # Aggregate values
                if not isinstance(result, list):
                    logger.warning(
                        f"Aggregate operation requires a list, got {type(result)}"
                    )
                    continue

                field = op.get("field")
                function = op.get("function", "sum")

                if not field:
                    logger.warning("Aggregate operation requires a field")
                    continue

                values = []
                for item in result:
                    if not isinstance(item, dict):
                        continue

                    if field in item and item[field] is not None:
                        values.append(item[field])

                if function == "sum":
                    result = sum(values) if values else 0
                elif function == "avg":
                    result = sum(values) / len(values) if values else 0
                elif function == "min":
                    result = min(values) if values else None
                elif function == "max":
                    result = max(values) if values else None
                elif function == "count":
                    result = len(values)
            elif op_type == "custom":
                # Custom Python code to process the JSON
                code = op.get("code", "")
                if code:
                    eval_globals = {
                        "json_data": result,
                        "json": json,
                        "datetime": datetime,
                        "re": re,
                    }

                    try:
                        result = eval(code, eval_globals, {})
                    except Exception as e:
                        logger.error(f"Error evaluating custom code: {e}")
                        if not step.continue_on_error:
                            raise

        return result

    async def validate_result(
        self, step: RecipeStep, result: Any, context: ExecutionContext
    ) -> ValidationResult:
        """
        Validate the result of a JSON process step.

        Args:
            step: Step to validate
            result: Result to validate
            context: Execution context

        Returns:
            Validation result
        """
        if not step.json_process:
            return ValidationResult(valid=True, issues=[])

        config = step.json_process

        # Check against validation schema if provided
        if config.validation_schema:
            try:
                from jsonschema import (
                    validate,
                    ValidationError as JsonSchemaValidationError,
                )

                try:
                    validate(instance=result, schema=config.validation_schema)
                    return ValidationResult(valid=True, issues=[])
                except JsonSchemaValidationError as e:
                    return ValidationResult(
                        valid=False,
                        issues=[
                            ValidationIssue(
                                message=f"JSON schema validation failed: {e.message}",
                                severity="error",
                                path=".".join(str(p) for p in e.path)
                                if e.path
                                else None,
                            )
                        ],
                    )
            except ImportError:
                logger.warning(
                    "jsonschema package not installed, skipping schema validation"
                )

        return ValidationResult(valid=True, issues=[])


class PythonExecuteExecutor:
    """Executor for Python execution steps."""

    async def execute(self, step: RecipeStep, context: ExecutionContext) -> Any:
        """
        Execute a Python execute step.

        Args:
            step: Step to execute
            context: Execution context

        Returns:
            Result of the Python execution
        """
        if not step.python_execute:
            raise ValueError(f"Missing python_execute configuration for step {step.id}")

        config = step.python_execute

        # Get the code to execute
        if config.code_file:
            code_file = context.interpolate_variables(config.code_file)
            try:
                with open(code_file, "r") as f:
                    code = f.read()
            except Exception as e:
                logger.error(f"Error reading code file {code_file}: {e}")
                if not step.continue_on_error:
                    raise
                return None
        else:
            code = config.code

        # Prepare the execution context
        exec_globals = {
            "json": json,
            "os": os,
            "datetime": datetime,
            "re": re,
            "math": __import__("math"),
            "random": __import__("random"),
            "collections": __import__("collections"),
            "functools": __import__("functools"),
            "itertools": __import__("itertools"),
            "result": None,  # This will be set by the code
        }

        # Add input variables to the context
        for var_name, var_source in config.input_variables.items():
            var_source = context.interpolate_variables(var_source)
            var_value = context.get_variable(var_source)
            if var_value is not None:
                exec_globals[var_name] = var_value
            else:
                exec_globals[var_name] = var_source

        # Apply import restrictions if specified
        if config.allowed_imports:
            original_import = __builtins__.__import__

            def restricted_import(name, *args, **kwargs):
                if name in config.allowed_imports:
                    return original_import(name, *args, **kwargs)
                else:
                    raise ImportError(f"Import of {name} is not allowed")

            __builtins__.__import__ = restricted_import

        # Set up timeout handling
        timeout = config.timeout
        if timeout is None and step.timeout:
            timeout = step.timeout
        if timeout is None and context.recipe and context.recipe.timeout:
            timeout = context.recipe.timeout

        # Set up memory limit if specified
        if config.memory_limit_mb:
            # This is a simple approximation and not a hard limit
            import resource

            resource.setrlimit(
                resource.RLIMIT_AS, (config.memory_limit_mb * 1024 * 1024, -1)
            )

        # Execute the code with timeout
        if timeout:
            try:
                with concurrent.futures.ThreadPoolExecutor() as executor:
                    future = executor.submit(exec, code, exec_globals, {})
                    result = await asyncio.get_event_loop().run_in_executor(
                        None, lambda: future.result(timeout=timeout)
                    )
            except concurrent.futures.TimeoutError:
                logger.error(
                    f"Python execution timed out after {timeout}s for step {step.id}"
                )
                raise TimeoutError(f"Python execution timed out after {timeout}s")
        else:
            exec(code, exec_globals, {})

        # Restore original import if it was modified
        if config.allowed_imports:
            __builtins__.__import__ = original_import

        result = exec_globals.get("result")
        return result

    async def validate_result(
        self, step: RecipeStep, result: Any, context: ExecutionContext
    ) -> ValidationResult:
        """
        Validate the result of a Python execute step.

        Args:
            step: Step to validate
            result: Result to validate
            context: Execution context

        Returns:
            Validation result
        """
        if not step.python_execute:
            return ValidationResult(valid=True, issues=[])

        config = step.python_execute

        # Run validation code if provided
        if config.validation_code:
            try:
                validation_globals = {
                    "result": result,
                    "valid": True,
                    "issues": [],
                    "json": json,
                    "datetime": datetime,
                    "re": re,
                }

                exec(config.validation_code, validation_globals, {})

                valid = validation_globals.get("valid", True)
                issues = validation_globals.get("issues", [])

                validation_issues = []
                for issue in issues:
                    if isinstance(issue, dict):
                        validation_issues.append(
                            ValidationIssue(
                                message=issue.get("message", "Unknown issue"),
                                severity=issue.get("severity", "error"),
                                path=issue.get("path"),
                            )
                        )
                    else:
                        validation_issues.append(
                            ValidationIssue(message=str(issue), severity="error")
                        )

                return ValidationResult(valid=valid, issues=validation_issues)
            except Exception as e:
                logger.error(f"Error in validation code: {e}")
                return ValidationResult(
                    valid=False,
                    issues=[
                        ValidationIssue(
                            message=f"Error in validation code: {e}", severity="error"
                        )
                    ],
                )

        return ValidationResult(valid=True, issues=[])


class ConditionalExecutor:
    """Executor for conditional steps."""

    async def execute(self, step: RecipeStep, context: ExecutionContext) -> Any:
        """
        Execute a conditional step.

        Args:
            step: Step to execute
            context: Execution context

        Returns:
            Result of the executed branch
        """
        if not step.conditional:
            raise ValueError(f"Missing conditional configuration for step {step.id}")

        config = step.conditional

        # Evaluate the condition
        condition = context.interpolate_variables(config.condition)
        condition_result = context.evaluate_condition(condition)

        logger.info(f"Condition '{condition}' evaluated to {condition_result}")

        if condition_result:
            # Execute the true branch
            true_step = config.true_step
            true_step_obj = RecipeStep.model_validate(true_step)

            # Create a clean executor for the sub-step
            from recipe_executor import RecipeExecutor

            executor = RecipeExecutor()

            return await executor.execute_step(true_step_obj, context)
        elif config.false_step:
            # Execute the false branch
            false_step = config.false_step
            false_step_obj = RecipeStep.model_validate(false_step)

            # Create a clean executor for the sub-step
            from recipe_executor import RecipeExecutor

            executor = RecipeExecutor()

            return await executor.execute_step(false_step_obj, context)
        else:
            # No false branch, return None
            return None

    async def validate_result(
        self, step: RecipeStep, result: Any, context: ExecutionContext
    ) -> ValidationResult:
        """
        Validate the result of a conditional step.

        Args:
            step: Step to validate
            result: Result to validate
            context: Execution context

        Returns:
            Validation result
        """
        # The validation is handled by the executed branch
        return ValidationResult(valid=True, issues=[])


class ChainExecutor:
    """Executor for chain steps."""

    async def execute(self, step: RecipeStep, context: ExecutionContext) -> Any:
        """
        Execute a chain of steps.

        Args:
            step: Step to execute
            context: Execution context

        Returns:
            Result of the last step in the chain
        """
        if not step.chain:
            raise ValueError(f"Missing chain configuration for step {step.id}")

        config = step.chain

        # Create a new context for the chain
        chain_context = context.create_child_context(VariableScope.CHAIN)

        # Copy shared variables if specified
        if config.shared_variables:
            for var_name in config.shared_variables:
                value = context.get_variable(var_name)
                if value is not None:
                    chain_context.set_variable(var_name, value)

        result = None

        # Execute each step in sequence
        for i, sub_step_data in enumerate(config.steps):
            # Create a RecipeStep from the sub-step data
            sub_step_id = sub_step_data.get("id", f"{step.id}_sub_{i + 1}")
            sub_step_data["id"] = sub_step_id
            sub_step = RecipeStep.model_validate(sub_step_data)

            # Create a clean executor for the sub-step
            from recipe_executor import RecipeExecutor

            executor = RecipeExecutor()

            try:
                # Execute the sub-step
                result = await executor.execute_step(sub_step, chain_context)

                # Copy the result to the chain context
                if isinstance(sub_step_data.get("output_variable"), str):
                    chain_context.set_variable(sub_step_data["output_variable"], result)
            except Exception as e:
                logger.error(f"Error executing sub-step {sub_step_id}: {e}")
                if not config.continue_on_step_failure:
                    raise
                result = None

        # Copy shared variables back to the parent context
        if config.shared_variables:
            for var_name in config.shared_variables:
                value = chain_context.get_variable(var_name)
                if value is not None:
                    context.set_variable(var_name, value)

        # Store the final result if an output variable is specified
        return result

    async def validate_result(
        self, step: RecipeStep, result: Any, context: ExecutionContext
    ) -> ValidationResult:
        """
        Validate the result of a chain step.

        Args:
            step: Step to validate
            result: Result to validate
            context: Execution context

        Returns:
            Validation result
        """
        # The validation is handled by each sub-step
        return ValidationResult(valid=True, issues=[])


class ParallelExecutor:
    """Executor for parallel steps."""

    async def execute(self, step: RecipeStep, context: ExecutionContext) -> List[Any]:
        """
        Execute steps in parallel.

        Args:
            step: Step to execute
            context: Execution context

        Returns:
            List of results from each step
        """
        if not step.parallel:
            raise ValueError(f"Missing parallel configuration for step {step.id}")

        config = step.parallel

        # Create a new context for each parallel step
        step_contexts = [
            context.create_child_context(VariableScope.STEP) for _ in config.steps
        ]

        # Create tasks for each sub-step
        tasks = []
        for i, (sub_step_data, step_context) in enumerate(
            zip(config.steps, step_contexts)
        ):
            # Create a RecipeStep from the sub-step data
            sub_step_id = sub_step_data.get("id", f"{step.id}_sub_{i + 1}")
            sub_step_data["id"] = sub_step_id
            sub_step = RecipeStep.model_validate(sub_step_data)

            # Create a clean executor for the sub-step
            from recipe_executor import RecipeExecutor

            executor = RecipeExecutor()

            # Create a task for the sub-step
            task = asyncio.create_task(executor.execute_step(sub_step, step_context))
            tasks.append((task, sub_step_id, sub_step, step_context))

        # Set up timeout
        timeout = config.timeout
        if timeout is None and step.timeout:
            timeout = step.timeout
        if timeout is None and context.recipe and context.recipe.timeout:
            timeout = context.recipe.timeout

        # Execute all tasks with timeout if specified
        if timeout:
            try:
                done, pending = await asyncio.wait(
                    [task for task, _, _, _ in tasks],
                    timeout=timeout,
                    return_when=asyncio.ALL_COMPLETED,
                )

                # Cancel any pending tasks
                for task in pending:
                    task.cancel()

                # Collect results
                results = []
                for task, sub_step_id, sub_step, step_context in tasks:
                    if task in done:
                        try:
                            result = task.result()
                            results.append(result)

                            # Copy result to parent context if output variable specified
                            if isinstance(sub_step.get("output_variable"), str):
                                context.set_variable(
                                    sub_step["output_variable"], result
                                )
                        except Exception as e:
                            logger.error(f"Error in parallel step {sub_step_id}: {e}")
                            if not step.continue_on_error:
                                raise
                            results.append(None)
                    else:
                        logger.warning(f"Parallel step {sub_step_id} timed out")
                        results.append(None)

                return results
            except asyncio.TimeoutError:
                logger.error(
                    f"Parallel execution timed out after {timeout}s for step {step.id}"
                )
                raise TimeoutError(f"Parallel execution timed out after {timeout}s")
        else:
            # Execute without timeout
            results = []
            for task, sub_step_id, sub_step, step_context in tasks:
                try:
                    result = await task
                    results.append(result)

                    # Copy result to parent context if output variable specified
                    if "output_variable" in sub_step and isinstance(
                        sub_step["output_variable"], str
                    ):
                        context.set_variable(sub_step["output_variable"], result)
                except Exception as e:
                    logger.error(f"Error in parallel step {sub_step_id}: {e}")
                    if not step.continue_on_error:
                        raise
                    results.append(None)

            return results

    async def validate_result(
        self, step: RecipeStep, result: Any, context: ExecutionContext
    ) -> ValidationResult:
        """
        Validate the result of a parallel step.

        Args:
            step: Step to validate
            result: Result to validate
            context: Execution context

        Returns:
            Validation result
        """
        # The validation is handled by each sub-step
        return ValidationResult(valid=True, issues=[])


class ValidatorExecutor:
    """Executor for validation steps."""

    async def execute(
        self, step: RecipeStep, context: ExecutionContext
    ) -> ValidationResult:
        """
        Execute a validation step.

        Args:
            step: Step to execute
            context: Execution context

        Returns:
            Validation result
        """
        if not step.validator:
            raise ValueError(f"Missing validator configuration for step {step.id}")

        config = step.validator

        # Get the target variable
        target_var = context.get_variable(config.target_variable)
        if target_var is None:
            raise ValueError(f"Target variable {config.target_variable} not found")

        # Perform validation based on type
        if config.validation_type == "schema":
            # Schema validation
            if not config.schema:
                raise ValueError("Schema validation requires a schema")

            try:
                from jsonschema import (
                    validate,
                    ValidationError as JsonSchemaValidationError,
                )

                try:
                    validate(instance=target_var, schema=config.schema)
                    result = ValidationResult(valid=True, issues=[])
                except JsonSchemaValidationError as e:
                    result = ValidationResult(
                        valid=False,
                        issues=[
                            ValidationIssue(
                                message=config.error_message
                                or f"Schema validation failed: {e.message}",
                                severity="error",
                                path=".".join(str(p) for p in e.path)
                                if e.path
                                else None,
                            )
                        ],
                    )
            except ImportError:
                logger.warning(
                    "jsonschema package not installed, validation will be skipped"
                )
                result = ValidationResult(
                    valid=False,
                    issues=[
                        ValidationIssue(
                            message="jsonschema package not installed, validation was skipped",
                            severity="warning",
                        )
                    ],
                )
        elif config.validation_type == "code":
            # Code validation
            if not config.code:
                raise ValueError("Code validation requires code")

            try:
                validation_globals = {
                    "target": target_var,
                    "valid": True,
                    "issues": [],
                    "json": json,
                    "datetime": datetime,
                    "re": re,
                }

                exec(config.code, validation_globals, {})

                valid = validation_globals.get("valid", True)
                issues = validation_globals.get("issues", [])

                validation_issues = []
                for issue in issues:
                    if isinstance(issue, dict):
                        validation_issues.append(
                            ValidationIssue(
                                message=issue.get("message", "Unknown issue"),
                                severity=issue.get("severity", "error"),
                                path=issue.get("path"),
                            )
                        )
                    else:
                        validation_issues.append(
                            ValidationIssue(message=str(issue), severity="error")
                        )

                result = ValidationResult(valid=valid, issues=validation_issues)
            except Exception as e:
                logger.error(f"Error in validation code: {e}")
                result = ValidationResult(
                    valid=False,
                    issues=[
                        ValidationIssue(
                            message=config.error_message
                            or f"Error in validation code: {e}",
                            severity="error",
                        )
                    ],
                )
        elif config.validation_type == "llm":
            # LLM validation
            if not config.llm_prompt:
                raise ValueError("LLM validation requires a prompt")

            # Create an LLM executor
            llm_executor = LLMGenerateExecutor()

            # Create a temporary step for the LLM validation
            llm_step = RecipeStep(
                id=f"{step.id}_llm",
                type=StepType.LLM_GENERATE,
                llm_generate=LLMGenerateConfig(
                    prompt=config.llm_prompt.replace(
                        "${target}",
                        json.dumps(target_var)
                        if isinstance(target_var, (dict, list))
                        else str(target_var),
                    ),
                    output_format=OutputFormat.STRUCTURED,
                    output_variable="_validation_result",
                    structured_schema={
                        "title": "ValidationResult",
                        "type": "object",
                        "properties": {
                            "valid": {"type": "boolean"},
                            "issues": {
                                "type": "array",
                                "items": {
                                    "type": "object",
                                    "properties": {
                                        "message": {"type": "string"},
                                        "severity": {
                                            "type": "string",
                                            "enum": ["error", "warning", "info"],
                                        },
                                        "path": {"type": "string"},
                                    },
                                    "required": ["message", "severity"],
                                },
                            },
                        },
                        "required": ["valid", "issues"],
                    },
                ),
            )

            # Execute the LLM validation
            llm_result = await llm_executor.execute(llm_step, context)

            # Convert to ValidationResult
            if isinstance(llm_result, dict) and "valid" in llm_result:
                valid = llm_result.get("valid", True)
                issues = llm_result.get("issues", [])

                validation_issues = []
                for issue in issues:
                    validation_issues.append(
                        ValidationIssue(
                            message=issue.get("message", "Unknown issue"),
                            severity=issue.get("severity", "error"),
                            path=issue.get("path"),
                        )
                    )

                result = ValidationResult(valid=valid, issues=validation_issues)
            else:
                result = ValidationResult(
                    valid=False,
                    issues=[
                        ValidationIssue(
                            message=config.error_message
                            or "LLM validation failed to return a valid result",
                            severity="error",
                        )
                    ],
                )
        else:
            raise ValueError(f"Unsupported validation type: {config.validation_type}")

        # Emit validation event
        event = ValidationEvent(valid=result.valid, issues_count=len(result.issues))
        context.emit_event(event)

        return result

    async def validate_result(
        self, step: RecipeStep, result: Any, context: ExecutionContext
    ) -> ValidationResult:
        """
        Validate the result of a validation step.

        Args:
            step: Step to validate
            result: Result to validate
            context: Execution context

        Returns:
            Validation result
        """
        # The result is already a ValidationResult
        return ValidationResult(valid=True, issues=[])


class ApiCallExecutor:
    """Executor for API call steps."""

    async def execute(
        self, step: RecipeStep, context: ExecutionContext
    ) -> Dict[str, Any]:
        """
        Execute an API call step.

        Args:
            step: Step to execute
            context: Execution context

        Returns:
            API response
        """
        if not step.api_call:
            raise ValueError(f"Missing api_call configuration for step {step.id}")

        config = step.api_call

        # Import aiohttp for async HTTP requests
        try:
            import aiohttp
        except ImportError:
            raise ImportError(
                "The aiohttp package is required for API calls. Install with: pip install aiohttp"
            )

        # Interpolate URL and prepare request
        url = context.interpolate_variables(config.url)
        method = config.method

        # Prepare headers
        headers = {}
        if config.headers:
            for name, value in config.headers.items():
                headers[name] = context.interpolate_variables(value)

        # Prepare data
        data = None
        if config.data_variable:
            data_var = context.get_variable(config.data_variable)
            if data_var is not None:
                if isinstance(data_var, dict):
                    data = data_var
                elif isinstance(data_var, str):
                    try:
                        data = json.loads(data_var)
                    except json.JSONDecodeError:
                        data = {"data": data_var}
                else:
                    data = {"data": str(data_var)}

        # Prepare auth
        auth = None
        if config.auth_variable:
            auth_var = context.get_variable(config.auth_variable)
            if isinstance(auth_var, tuple) and len(auth_var) == 2:
                auth = aiohttp.BasicAuth(auth_var[0], auth_var[1])
            elif (
                isinstance(auth_var, dict)
                and "username" in auth_var
                and "password" in auth_var
            ):
                auth = aiohttp.BasicAuth(auth_var["username"], auth_var["password"])

        # Set up timeout
        timeout = config.timeout
        if timeout is None and step.timeout:
            timeout = step.timeout
        if timeout is None and context.recipe and context.recipe.timeout:
            timeout = context.recipe.timeout

        # Create aiohttp timeout
        if timeout:
            timeout_obj = aiohttp.ClientTimeout(total=timeout)
        else:
            timeout_obj = None

        # Execute the request with retry logic
        retry_count = 0
        max_retries = config.retry_count
        retry_delay = config.retry_delay

        while True:
            try:
                async with aiohttp.ClientSession(
                    auth=auth, timeout=timeout_obj
                ) as session:
                    if method == "GET":
                        async with session.get(
                            url, headers=headers, json=data
                        ) as response:
                            status = response.status
                            try:
                                result = await response.json()
                            except:
                                result = {
                                    "text": await response.text(),
                                    "status": status,
                                }
                    elif method == "POST":
                        async with session.post(
                            url, headers=headers, json=data
                        ) as response:
                            status = response.status
                            try:
                                result = await response.json()
                            except:
                                result = {
                                    "text": await response.text(),
                                    "status": status,
                                }
                    elif method == "PUT":
                        async with session.put(
                            url, headers=headers, json=data
                        ) as response:
                            status = response.status
                            try:
                                result = await response.json()
                            except:
                                result = {
                                    "text": await response.text(),
                                    "status": status,
                                }
                    elif method == "DELETE":
                        async with session.delete(
                            url, headers=headers, json=data
                        ) as response:
                            status = response.status
                            try:
                                result = await response.json()
                            except:
                                result = {
                                    "text": await response.text(),
                                    "status": status,
                                }
                    elif method == "PATCH":
                        async with session.patch(
                            url, headers=headers, json=data
                        ) as response:
                            status = response.status
                            try:
                                result = await response.json()
                            except:
                                result = {
                                    "text": await response.text(),
                                    "status": status,
                                }
                    else:
                        raise ValueError(f"Unsupported HTTP method: {method}")

                # Check for error status
                if status >= 400:
                    logger.warning(f"API call returned error status {status}: {result}")

                    # Retry if appropriate
                    if retry_count < max_retries and (
                        (status >= 500) or (status == 429)
                    ):
                        retry_count += 1
                        logger.info(
                            f"Retrying API call ({retry_count}/{max_retries}) after {retry_delay}s"
                        )
                        await asyncio.sleep(retry_delay)
                        continue

                    if not step.continue_on_error:
                        raise ValueError(f"API call failed with status {status}")

                # Add status to result if it's a dictionary
                if isinstance(result, dict) and "status" not in result:
                    result["status"] = status

                return result
            except (aiohttp.ClientError, asyncio.TimeoutError) as e:
                logger.error(f"API call error: {e}")

                # Retry if appropriate
                if retry_count < max_retries:
                    retry_count += 1
                    logger.info(
                        f"Retrying API call ({retry_count}/{max_retries}) after {retry_delay}s"
                    )
                    await asyncio.sleep(retry_delay)
                    continue

                if not step.continue_on_error:
                    raise

                return {"error": str(e), "status": 0}

    async def validate_result(
        self, step: RecipeStep, result: Any, context: ExecutionContext
    ) -> ValidationResult:
        """
        Validate the result of an API call step.

        Args:
            step: Step to validate
            result: Result to validate
            context: Execution context

        Returns:
            Validation result
        """
        if not step.api_call:
            return ValidationResult(valid=True, issues=[])

        # Check that the result is a dictionary
        if not isinstance(result, dict):
            return ValidationResult(
                valid=False,
                issues=[
                    ValidationIssue(
                        message="API call result is not a dictionary", severity="error"
                    )
                ],
            )

        # Check the status code
        status = result.get("status", 0)
        if status >= 400:
            return ValidationResult(
                valid=False,
                issues=[
                    ValidationIssue(
                        message=f"API call failed with status {status}",
                        severity="error",
                    )
                ],
            )

        # Check for error field
        if "error" in result:
            return ValidationResult(
                valid=False,
                issues=[
                    ValidationIssue(
                        message=f"API call returned error: {result['error']}",
                        severity="error",
                    )
                ],
            )

        return ValidationResult(valid=True, issues=[])


class WaitForInputExecutor:
    """Executor for wait for input steps."""

    async def execute(self, step: RecipeStep, context: ExecutionContext) -> Any:
        """
        Execute a wait for input step.

        Args:
            step: Step to execute
            context: Execution context

        Returns:
            User input
        """
        if not step.wait_for_input:
            raise ValueError(f"Missing wait_for_input configuration for step {step.id}")

        config = step.wait_for_input

        # Interpolate the prompt
        prompt = context.interpolate_variables(config.prompt)

        # Emit user interaction event
        event = UserInteractionEvent(prompt=prompt)
        context.emit_event(event)

        # Set up timeout
        timeout = config.timeout
        if timeout is None and step.timeout:
            timeout = step.timeout
        if timeout is None and context.recipe and context.recipe.timeout:
            timeout = context.recipe.timeout

        # Wait for input with timeout if specified
        if timeout:
            try:
                input_task = asyncio.create_task(asyncio.to_thread(input, prompt + " "))
                result = await asyncio.wait_for(input_task, timeout=timeout)
            except asyncio.TimeoutError:
                logger.warning(
                    f"Wait for input timed out after {timeout}s for step {step.id}"
                )
                result = config.default_value
        else:
            result = input(prompt + " ")

        # Process options if specified
        if config.options and result:
            if result.isdigit() and 0 <= int(result) < len(config.options):
                # User entered a numeric index
                result = config.options[int(result)]
            elif result not in config.options:
                # User entered something not in the options
                print(f"Invalid option: {result}")
                print(f"Valid options: {', '.join(config.options)}")
                if config.default_value is not None:
                    result = config.default_value
                else:
                    # Try again
                    return await self.execute(step, context)

        # Use default value if input is empty
        if not result and config.default_value is not None:
            result = config.default_value

        return result

    async def validate_result(
        self, step: RecipeStep, result: Any, context: ExecutionContext
    ) -> ValidationResult:
        """
        Validate the result of a wait for input step.

        Args:
            step: Step to validate
            result: Result to validate
            context: Execution context

        Returns:
            Validation result
        """
        if not step.wait_for_input:
            return ValidationResult(valid=True, issues=[])

        config = step.wait_for_input

        # Check that the result is not None if required
        if result is None and not config.default_value:
            return ValidationResult(
                valid=False,
                issues=[
                    ValidationIssue(
                        message="Input is required but was not provided",
                        severity="error",
                    )
                ],
            )

        # Check that the result is in the options if specified
        if config.options and result not in config.options:
            return ValidationResult(
                valid=False,
                issues=[
                    ValidationIssue(
                        message=f"Input '{result}' is not in the valid options: {', '.join(config.options)}",
                        severity="error",
                    )
                ],
            )

        return ValidationResult(valid=True, issues=[])


class ApiCallExecutor:
    """Executor for API call steps."""

    async def execute(
        self, step: RecipeStep, context: ExecutionContext
    ) -> Dict[str, Any]:
        """
        Execute an API call step.

        Args:
            step: Step to execute
            context: Execution context

        Returns:
            API response
        """
        if not step.api_call:
            raise ValueError(f"Missing api_call configuration for step {step.id}")

        config = step.api_call

        # Import aiohttp for async HTTP requests
        try:
            import aiohttp
        except ImportError:
            raise ImportError(
                "The aiohttp package is required for API calls. Install with: pip install aiohttp"
            )

        # Interpolate URL and prepare request
        url = context.interpolate_variables(config.url)
        method = config.method

        # Prepare headers
        headers = {}
        if config.headers:
            for name, value in config.headers.items():
                headers[name] = context.interpolate_variables(value)

        # Prepare data
        data = None
        if config.data_variable:
            data_var = context.get_variable(config.data_variable)
            if data_var is not None:
                if isinstance(data_var, dict):
                    data = data_var
                elif isinstance(data_var, str):
                    try:
                        data = json.loads(data_var)
                    except json.JSONDecodeError:
                        data = {"data": data_var}
                else:
                    data = {"data": str(data_var)}

        # Prepare auth
        auth = None
        if config.auth_variable:
            auth_var = context.get_variable(config.auth_variable)
            if isinstance(auth_var, tuple) and len(auth_var) == 2:
                auth = aiohttp.BasicAuth(auth_var[0], auth_var[1])
            elif (
                isinstance(auth_var, dict)
                and "username" in auth_var
                and "password" in auth_var
            ):
                auth = aiohttp.BasicAuth(auth_var["username"], auth_var["password"])

        # Set up timeout
        timeout = config.timeout
        if timeout is None and step.timeout:
            timeout = step.timeout
        if timeout is None and context.recipe and context.recipe.timeout:
            timeout = context.recipe.timeout

        # Create aiohttp timeout
        if timeout:
            timeout_obj = aiohttp.ClientTimeout(total=timeout)
        else:
            timeout_obj = None

        # Execute the request with retry logic
        retry_count = 0
        max_retries = config.retry_count
        retry_delay = config.retry_delay

        while True:
            try:
                async with aiohttp.ClientSession(
                    auth=auth, timeout=timeout_obj
                ) as session:
                    if method == "GET":
                        async with session.get(
                            url, headers=headers, json=data
                        ) as response:
                            status = response.status
                            try:
                                result = await response.json()
                            except:
                                result = {
                                    "text": await response.text(),
                                    "status": status,
                                }
                    elif method == "POST":
                        async with session.post(
                            url, headers=headers, json=data
                        ) as response:
                            status = response.status
                            try:
                                result = await response.json()
                            except:
                                result = {
                                    "text": await response.text(),
                                    "status": status,
                                }
                    elif method == "PUT":
                        async with session.put(
                            url, headers=headers, json=data
                        ) as response:
                            status = response.status
                            try:
                                result = await response.json()
                            except:
                                result = {
                                    "text": await response.text(),
                                    "status": status,
                                }
                    elif method == "DELETE":
                        async with session.delete(
                            url, headers=headers, json=data
                        ) as response:
                            status = response.status
                            try:
                                result = await response.json()
                            except:
                                result = {
                                    "text": await response.text(),
                                    "status": status,
                                }
                    elif method == "PATCH":
                        async with session.patch(
                            url, headers=headers, json=data
                        ) as response:
                            status = response.status
                            try:
                                result = await response.json()
                            except:
                                result = {
                                    "text": await response.text(),
                                    "status": status,
                                }
                    else:
                        raise ValueError(f"Unsupported HTTP method: {method}")

                # Check for error status
                if status >= 400:
                    logger.warning(f"API call returned error status {status}: {result}")

                    # Retry if appropriate
                    if retry_count < max_retries and (
                        (status >= 500) or (status == 429)
                    ):
                        retry_count += 1
                        logger.info(
                            f"Retrying API call ({retry_count}/{max_retries}) after {retry_delay}s"
                        )
                        await asyncio.sleep(retry_delay)
                        continue

                    if not step.continue_on_error:
                        raise ValueError(f"API call failed with status {status}")

                # Add status to result if it's a dictionary
                if isinstance(result, dict) and "status" not in result:
                    result["status"] = status

                return result
            except (aiohttp.ClientError, asyncio.TimeoutError) as e:
                logger.error(f"API call error: {e}")

                # Retry if appropriate
                if retry_count < max_retries:
                    retry_count += 1
                    logger.info(
                        f"Retrying API call ({retry_count}/{max_retries}) after {retry_delay}s"
                    )
                    await asyncio.sleep(retry_delay)
                    continue

                if not step.continue_on_error:
                    raise

                return {"error": str(e), "status": 0}

    async def validate_result(
        self, step: RecipeStep, result: Any, context: ExecutionContext
    ) -> ValidationResult:
        """
        Validate the result of an API call step.

        Args:
            step: Step to validate
            result: Result to validate
            context: Execution context

        Returns:
            Validation result
        """
        if not step.api_call:
            return ValidationResult(valid=True, issues=[])

        # Check that the result is a dictionary
        if not isinstance(result, dict):
            return ValidationResult(
                valid=False,
                issues=[
                    ValidationIssue(
                        message="API call result is not a dictionary", severity="error"
                    )
                ],
            )

        # Check the status code
        status = result.get("status", 0)
        if status >= 400:
            return ValidationResult(
                valid=False,
                issues=[
                    ValidationIssue(
                        message=f"API call failed with status {status}",
                        severity="error",
                    )
                ],
            )

        # Check for error field
        if "error" in result:
            return ValidationResult(
                valid=False,
                issues=[
                    ValidationIssue(
                        message=f"API call returned error: {result['error']}",
                        severity="error",
                    )
                ],
            )

        return ValidationResult(valid=True, issues=[])


class RecipeExecutor:
    """
    Main class for executing LLM recipes with code-driven reliability.
    """

    def __init__(
        self,
        default_model_name: str = "claude-3-7-sonnet-20250219",
        default_model_provider: Literal[
            "anthropic", "openai", "google", "mistral", "ollama", "groq"
        ] = "anthropic",
        recipes_dir: str = "recipes",
        output_dir: str = "output",
        cache_dir: Optional[str] = "cache",
        temp: float = 0.1,
        validation_level: ValidationLevel = ValidationLevel.STANDARD,
        interaction_mode: InteractionMode = InteractionMode.CRITICAL,
        log_level: int = logging.INFO,
    ):
        """
        Initialize the recipe executor.

        Args:
            default_model_name: The default model name to use
            default_model_provider: The default provider of the model
            recipes_dir: Directory containing recipe files
            output_dir: Directory to output generated files to
            cache_dir: Directory for caching LLM responses, or None to disable caching
            temp: Default temperature setting for the model
            validation_level: Default validation level
            interaction_mode: Default interaction mode
            log_level: Logging level
        """
        self.default_model_name = default_model_name
        self.default_model_provider = default_model_provider
        self.recipes_dir = recipes_dir
        self.output_dir = output_dir
        self.cache_dir = cache_dir
        self.temp = temp
        self.validation_level = validation_level
        self.interaction_mode = interaction_mode

        # Initialize logging
        logger.setLevel(log_level)

        # Create directories
        os.makedirs(output_dir, exist_ok=True)
        if cache_dir:
            os.makedirs(cache_dir, exist_ok=True)

        # Import and load dotenv if available
        try:
            from dotenv import load_dotenv

            # Try to load from .env file - first look in current directory, then parent directories
            env_path = Path(".") / ".env"
            if env_path.exists():
                load_dotenv(dotenv_path=env_path)
            else:
                # Try to find .env in parent directories
                current_dir = Path(".")
                for _ in range(3):  # Look up to 3 parent directories
                    current_dir = current_dir.parent
                    env_path = current_dir / ".env"
                    if env_path.exists():
                        load_dotenv(dotenv_path=env_path)
                        break
                else:
                    # If we get here, no .env file was found
                    logger.info(
                        "No .env file found. Using environment variables directly."
                    )
        except ImportError:
            logger.warning(
                "python-dotenv not installed. Environment variables must be set in the environment."
            )
            logger.warning("Install with: pip install python-dotenv")

        # Call this method
        self._check_api_keys()

        # Initialize executors for each step type
        self.executors = {
            StepType.LLM_GENERATE: LLMGenerateExecutor(cache_dir=cache_dir),
            StepType.FILE_READ: FileReadExecutor(),
            StepType.FILE_WRITE: FileWriteExecutor(),
            StepType.TEMPLATE_SUBSTITUTE: TemplateSubstituteExecutor(),
            StepType.JSON_PROCESS: JsonProcessExecutor(),
            StepType.PYTHON_EXECUTE: PythonExecuteExecutor(),
            StepType.CONDITIONAL: ConditionalExecutor(),
            StepType.CHAIN: ChainExecutor(),
            StepType.PARALLEL: ParallelExecutor(),
            StepType.VALIDATOR: ValidatorExecutor(),
            StepType.WAIT_FOR_INPUT: WaitForInputExecutor(),
            StepType.API_CALL: ApiCallExecutor(),
        }

        # Default event listener for console output
        self.event_listener = ConsoleEventListener()

    # Check and warn about missing API keys
    def _check_api_keys(self):
        """Check if required API keys are available and log warnings if not."""
        if self.default_model_provider == "anthropic" and not os.environ.get(
            "ANTHROPIC_API_KEY"
        ):
            logger.warning(
                "ANTHROPIC_API_KEY not found in environment variables. Anthropic models will not work."
            )
        elif self.default_model_provider == "openai" and not os.environ.get(
            "OPENAI_API_KEY"
        ):
            logger.warning(
                "OPENAI_API_KEY not found in environment variables. OpenAI models will not work."
            )
        elif self.default_model_provider == "google" and not os.environ.get(
            "GOOGLE_API_KEY"
        ):
            logger.warning(
                "GOOGLE_API_KEY not found in environment variables. Google models will not work."
            )
        elif self.default_model_provider == "mistral" and not os.environ.get(
            "MISTRAL_API_KEY"
        ):
            logger.warning(
                "MISTRAL_API_KEY not found in environment variables. Mistral models will not work."
            )
        elif self.default_model_provider == "groq" and not os.environ.get(
            "GROQ_API_KEY"
        ):
            logger.warning(
                "GROQ_API_KEY not found in environment variables. Groq models will not work."
            )

    async def _parse_natural_language_recipe(self, nl_content: str) -> Recipe:
        """
        Parse a natural language recipe into a structured recipe.

        Args:
            nl_content: Natural language recipe content

        Returns:
            Structured recipe
        """
        # Create a temporary context
        context = ExecutionContext(
            variables={},
            recipe=None,
            interaction_mode=self.interaction_mode,
            validation_level=self.validation_level,
        )

        # Add event listener
        context.add_event_listener(self.event_listener)

        # Create an LLM executor for parsing
        llm_executor = self.executors[StepType.LLM_GENERATE]

        # Create a temporary step for LLM parsing
        parse_step = RecipeStep(
            id="parse_natural_language",
            name="Parse Natural Language Recipe",
            type=StepType.LLM_GENERATE,
            llm_generate=LLMGenerateConfig(
                prompt=f"""
                Convert this natural language recipe into a structured YAML recipe:
                
                {nl_content}
                
                The recipe should follow this structure:
                - metadata (name, description, etc.)
                - model configuration (if specified)
                - variables (if needed)
                - steps with appropriate types and configurations
                
                Use these step types as appropriate:
                - llm_generate: For generating content with LLMs
                - file_read: For reading files
                - file_write: For writing files
                - template_substitute: For substituting variables in templates
                - json_process: For processing JSON data
                - python_execute: For executing Python code
                - conditional: For conditional execution
                - chain: For executing steps in sequence
                - parallel: For executing steps in parallel
                - validator: For validating data
                - wait_for_input: For waiting for user input
                - api_call: For making API calls
                
                Return ONLY the YAML recipe as your response.
                """,
                output_format=OutputFormat.TEXT,
                output_variable="yaml_recipe",
            ),
        )

        # Execute the parsing step
        yaml_recipe = await llm_executor.execute(parse_step, context)

        # Convert YAML to Recipe
        if YAML_SUPPORT:
            try:
                data = yaml.safe_load(yaml_recipe)
                recipe = Recipe.model_validate(data)

                # Store the original and structured versions
                recipe.variables["_original_recipe"] = nl_content
                recipe.variables["_structured_recipe"] = yaml_recipe

                return recipe
            except Exception as e:
                logger.error(f"Error parsing generated YAML recipe: {e}")
                raise ValueError(f"Failed to parse natural language recipe: {e}")
        else:
            raise ImportError(
                "YAML support requires pydantic-yaml package. Install with: pip install pydantic-yaml"
            )

    async def load_recipe(self, recipe_path: str) -> Recipe:
        """
        Load a recipe from a file.

        Args:
            recipe_path: Path to the recipe file

        Returns:
            Recipe object
        """
        if not os.path.isabs(recipe_path):
            recipe_path = os.path.join(self.recipes_dir, recipe_path)

        file_ext = os.path.splitext(recipe_path)[1].lower()

        try:
            # Read the file content
            with open(recipe_path, "r") as f:
                content = f.read()

            # Check if this is a structured or natural language recipe
            is_structured = False

            if file_ext == ".json":
                try:
                    data = json.loads(content)
                    recipe = Recipe.model_validate(data)
                    is_structured = True
                except json.JSONDecodeError:
                    logger.info("JSON parsing failed, treating as natural language")
                except ValidationError:
                    logger.info("JSON validation failed, treating as natural language")
            elif file_ext in [".yaml", ".yml"]:
                if YAML_SUPPORT:
                    try:
                        data = yaml.safe_load(content)
                        recipe = Recipe.model_validate(data)
                        is_structured = True
                    except yaml.YAMLError:
                        logger.info("YAML parsing failed, treating as natural language")
                    except ValidationError:
                        logger.info(
                            "YAML validation failed, treating as natural language"
                        )
                else:
                    logger.warning(
                        "YAML support requires pydantic-yaml package. Install with: pip install pydantic-yaml"
                    )
            elif file_ext == ".md":
                # For markdown files, try to extract YAML/JSON from code blocks
                yaml_match = re.search(r"```ya?ml\s*\n(.*?)\n```", content, re.DOTALL)
                if yaml_match and YAML_SUPPORT:
                    yaml_content = yaml_match.group(1)
                    try:
                        data = yaml.safe_load(yaml_content)
                        recipe = Recipe.model_validate(data)
                        is_structured = True
                    except (yaml.YAMLError, ValidationError):
                        logger.info("YAML code block parsing failed, trying JSON")

                if not is_structured:
                    # Try to find a JSON code block
                    json_match = re.search(
                        r"```json\s*\n(.*?)\n```", content, re.DOTALL
                    )
                    if json_match:
                        json_content = json_match.group(1)
                        try:
                            data = json.loads(json_content)
                            recipe = Recipe.model_validate(data)
                            is_structured = True
                        except (json.JSONDecodeError, ValidationError):
                            logger.info(
                                "JSON code block parsing failed, treating as natural language"
                            )

            # If not structured, parse as natural language
            if not is_structured:
                logger.info("Parsing as natural language recipe")
                recipe = await self._parse_natural_language_recipe(content)

            logger.info(f"Loaded recipe: {recipe.metadata.name}")
            return recipe
        except Exception as e:
            logger.error(f"Error loading recipe from {recipe_path}: {e}")
            raise

    async def execute_step(
        self, step: RecipeStep, context: ExecutionContext
    ) -> Tuple[Any, StepResult]:
        """
        Execute a single step in the recipe.

        Args:
            step: Step to execute
            context: Execution context

        Returns:
            Tuple of (result, step_result)
        """
        logger.info(f"Executing step: {step.id} ({step.name or step.type})")

        # Store the current step in the context
        context.set_current_step(step)

        # Emit step start event
        event = StepStartEvent(
            step_id=step.id, step_name=step.name, step_type=step.type
        )
        context.emit_event(event)

        # Start timing
        start_time = time.time()

        # Initialize step result
        step_result = StepResult(
            step_id=step.id, status=StepStatus.IN_PROGRESS, started_at=datetime.now()
        )

        # Check if the step should run based on its condition
        if step.condition and not context.evaluate_condition(step.condition):
            logger.info(f"Skipping step {step.id} due to condition")

            # Update step result
            step_result.status = StepStatus.SKIPPED
            step_result.completed_at = datetime.now()
            step_result.duration_seconds = time.time() - start_time

            # Emit step complete event
            event = StepCompleteEvent(
                step_id=step.id,
                status=step_result.status,
                duration_seconds=step_result.duration_seconds,
            )
            context.emit_event(event)

            # Store the step result
            context.set_step_result(step.id, step_result)

            return None, step_result

        # Check if dependencies are satisfied
        if step.depends_on:
            for dep_id in step.depends_on:
                dep_result = context.get_step_result(dep_id)
                if not dep_result or dep_result.status != StepStatus.COMPLETED:
                    logger.error(
                        f"Cannot execute step {step.id}, dependency {dep_id} not yet completed"
                    )

                    # Update step result
                    step_result.status = StepStatus.FAILED
                    step_result.error = f"Dependency {dep_id} not completed"
                    step_result.completed_at = datetime.now()
                    step_result.duration_seconds = time.time() - start_time

                    # Emit step failed event
                    event = StepFailedEvent(step_id=step.id, error=step_result.error)
                    context.emit_event(event)

                    # Store the step result
                    context.set_step_result(step.id, step_result)

                    # Raise error if step is critical
                    if step.critical and not step.continue_on_error:
                        raise ValueError(
                            f"Critical step {step.id} failed: {step_result.error}"
                        )

                    return None, step_result

        # Initialize the retry counter
        retry_count = 0

        # Execute with retry logic
        while True:
            try:
                # Get the executor for this step type
                if step.type not in self.executors:
                    raise ValueError(f"Unsupported step type: {step.type}")

                executor = self.executors[step.type]

                # Execute the step
                result = await executor.execute(step, context)

                # Store the result in the variable if specified
                if hasattr(step, f"{step.type.value}") and hasattr(
                    getattr(step, f"{step.type.value}"), "output_variable"
                ):
                    output_variable = getattr(
                        getattr(step, f"{step.type.value}"), "output_variable"
                    )
                    if output_variable:
                        context.set_variable(output_variable, result)

                # Validate the result
                validation_result = await executor.validate_result(
                    step, result, context
                )

                # Handle validation failures
                if (
                    not validation_result.valid
                    and step.validation_level >= ValidationLevel.STANDARD
                ):
                    issue_messages = "; ".join(
                        issue.message for issue in validation_result.issues
                    )
                    logger.warning(
                        f"Step {step.id} validation failed: {issue_messages}"
                    )

                    # Emit validation event
                    event = ValidationEvent(
                        valid=False, issues_count=len(validation_result.issues)
                    )
                    context.emit_event(event)

                    if step.validation_level == ValidationLevel.STRICT:
                        raise ValueError(
                            f"Validation failed for step {step.id}: {issue_messages}"
                        )

                # Mark the step as completed
                step_result.status = StepStatus.COMPLETED
                step_result.result = result
                step_result.completed_at = datetime.now()
                step_result.duration_seconds = time.time() - start_time
                step_result.validation_result = validation_result

                # Emit step complete event
                event = StepCompleteEvent(
                    step_id=step.id,
                    status=step_result.status,
                    duration_seconds=step_result.duration_seconds,
                )
                context.emit_event(event)

                # Store the step result
                context.set_step_result(step.id, step_result)

                return result, step_result
            except Exception as e:
                logger.error(f"Error executing step {step.id}: {e}")
                logger.error(traceback.format_exc())

                retry_count += 1

                # Update step result
                step_result.status = StepStatus.FAILED
                step_result.error = str(e)
                step_result.completed_at = datetime.now()
                step_result.duration_seconds = time.time() - start_time

                # Emit step failed event
                event = StepFailedEvent(
                    step_id=step.id, error=str(e), traceback=traceback.format_exc()
                )
                context.emit_event(event)

                # Store the step result
                context.set_step_result(step.id, step_result)

                # Determine if we should retry
                max_retries = step.retry_count
                if retry_count <= max_retries:
                    logger.info(
                        f"Retrying step {step.id} ({retry_count}/{max_retries})"
                    )
                    await asyncio.sleep(step.retry_delay)  # Add a delay before retrying
                    continue

                # Handle failure
                if step.continue_on_error:
                    logger.info(f"Continuing execution despite error in step {step.id}")
                    return None, step_result
                elif step.critical:
                    raise ValueError(f"Critical step {step.id} failed: {e}")
                else:
                    return None, step_result

    async def execute_recipe(self, recipe: Recipe) -> RecipeResult:
        """
        Execute a recipe.

        Args:
            recipe: Recipe to execute

        Returns:
            Result of the recipe execution
        """
        logger.info(f"Executing recipe: {recipe.metadata.name}")

        # Set up recipe execution context
        context = ExecutionContext(
            variables=dict(recipe.variables),
            recipe=recipe,
            interaction_mode=recipe.interaction_mode,
            validation_level=recipe.validation_level,
        )

        # Add standard event listener
        context.add_event_listener(self.event_listener)

        # Emit recipe start event
        event = RecipeStartEvent(recipe_name=recipe.metadata.name)
        context.emit_event(event)

        # Start timing
        start_time = time.time()

        # Initialize recipe result
        recipe_result = RecipeResult(
            recipe_name=recipe.metadata.name,
            status=ExecutionStatus.EXECUTING,
            started_at=datetime.now(),
        )

        # Set up timeout handling
        timeout = recipe.timeout
        if timeout:
            logger.info(f"Recipe timeout set to {timeout}s")

        # Create a task for the recipe execution
        async def execute_recipe_steps():
            try:
                # Execute each step in sequence
                for step in recipe.steps:
                    # Skip steps that have explicit dependencies, they will be executed when needed
                    if step.depends_on:
                        continue

                    result, step_result = await self.execute_step(step, context)
                    recipe_result.steps[step.id] = step_result

                    if (
                        step_result.status == StepStatus.FAILED
                        and not step.continue_on_error
                    ):
                        logger.error(
                            f"Step {step.id} failed, stopping recipe execution"
                        )
                        raise ValueError(f"Step {step.id} failed: {step_result.error}")

                # Update recipe result
                recipe_result.status = ExecutionStatus.COMPLETED
                recipe_result.completed_at = datetime.now()
                recipe_result.duration_seconds = time.time() - start_time
                recipe_result.variables = context.variables

                # Emit recipe complete event
                event = RecipeCompleteEvent(
                    recipe_name=recipe.metadata.name,
                    status=recipe_result.status,
                    duration_seconds=recipe_result.duration_seconds,
                )
                context.emit_event(event)

                return recipe_result
            except Exception as e:
                logger.error(f"Error executing recipe: {e}")
                logger.error(traceback.format_exc())

                # Update recipe result
                recipe_result.status = ExecutionStatus.FAILED
                recipe_result.error = str(e)
                recipe_result.completed_at = datetime.now()
                recipe_result.duration_seconds = time.time() - start_time
                recipe_result.variables = context.variables

                # Emit recipe complete event
                event = RecipeCompleteEvent(
                    recipe_name=recipe.metadata.name,
                    status=recipe_result.status,
                    duration_seconds=recipe_result.duration_seconds,
                )
                context.emit_event(event)

                return recipe_result

        # Execute with timeout if specified
        if timeout:
            try:
                return await asyncio.wait_for(execute_recipe_steps(), timeout)
            except asyncio.TimeoutError:
                logger.error(f"Recipe execution timed out after {timeout}s")

                # Update recipe result
                recipe_result.status = ExecutionStatus.FAILED
                recipe_result.error = f"Execution timed out after {timeout}s"
                recipe_result.completed_at = datetime.now()
                recipe_result.duration_seconds = time.time() - start_time
                recipe_result.variables = context.variables

                return recipe_result
        else:
            return await execute_recipe_steps()

    async def parse_and_execute_natural_language(
        self, nl_content: str, variables: Dict[str, Any] = None
    ) -> RecipeResult:
        """
        Parse and execute a natural language recipe.

        Args:
            nl_content: Natural language recipe content
            variables: Initial variables to use

        Returns:
            Result of the recipe execution
        """
        # Parse the natural language recipe
        recipe = await self._parse_natural_language_recipe(nl_content)

        # Add variables if provided
        if variables:
            recipe.variables.update(variables)

        # Execute the recipe
        return await self.execute_recipe(recipe)


async def main():
    """Main entry point for the recipe executor."""
    import argparse

    parser = argparse.ArgumentParser(description="Recipe Executor")
    parser.add_argument("recipe_file", help="Path to the recipe file")
    parser.add_argument(
        "--model", default="claude-3-7-sonnet-20250219", help="Default model to use"
    )
    parser.add_argument(
        "--provider", default="anthropic", help="Default model provider"
    )
    parser.add_argument(
        "--recipes-dir", default="recipes", help="Directory containing recipe files"
    )
    parser.add_argument(
        "--output-dir", default="output", help="Directory to output generated files to"
    )
    parser.add_argument(
        "--cache-dir",
        default="cache",
        help="Directory for caching LLM responses, or 'none' to disable",
    )
    parser.add_argument(
        "--temp", type=float, default=0.1, help="Default temperature setting"
    )
    parser.add_argument(
        "--vars",
        action="append",
        help="Initial variables in the format name=value",
        default=[],
    )
    parser.add_argument(
        "--validation",
        choices=["minimal", "standard", "strict"],
        default="standard",
        help="Validation level",
    )
    parser.add_argument(
        "--interaction",
        choices=["none", "critical", "regular", "verbose"],
        default="critical",
        help="Interaction mode",
    )
    parser.add_argument(
        "--log-level",
        choices=["debug", "info", "warning", "error"],
        default="info",
        help="Logging level",
    )

    args = parser.parse_args()

    # Convert string arguments to enums
    validation_level = ValidationLevel[args.validation.upper()]
    interaction_mode = InteractionMode[args.interaction.upper()]
    log_level = getattr(logging, args.log_level.upper())

    # Handle cache directory
    cache_dir = None if args.cache_dir.lower() == "none" else args.cache_dir

    # Create the executor
    executor = RecipeExecutor(
        default_model_name=args.model,
        default_model_provider=args.provider,
        recipes_dir=args.recipes_dir,
        output_dir=args.output_dir,
        cache_dir=cache_dir,
        temp=args.temp,
        validation_level=validation_level,
        interaction_mode=interaction_mode,
        log_level=log_level,
    )

    # Add initial variables from command line
    initial_vars = {}
    for var_str in args.vars:
        name, value = var_str.split("=", 1)
        # Try to convert to appropriate type
        try:
            # Try to parse as JSON
            initial_vars[name] = json.loads(value)
        except json.JSONDecodeError:
            # Fall back to string
            initial_vars[name] = value

    # Load and execute the recipe
    recipe = await executor.load_recipe(args.recipe_file)

    # Add initial variables
    if initial_vars:
        recipe.variables.update(initial_vars)

    # Execute the recipe
    result = await executor.execute_recipe(recipe)

    # Print the result
    print(f"\nRecipe: {result.recipe_name}")
    print(f"Status: {result.status}")
    print(f"Duration: {result.duration_seconds:.2f}s")

    if result.error:
        print(f"Error: {result.error}")

    print("\nStep Results:")
    for step_id, step_result in result.steps.items():
        print(
            f"  {step_id}: {step_result.status} ({step_result.duration_seconds:.2f}s)"
        )
        if step_result.error:
            print(f"    Error: {step_result.error}")

    # Print variables marked for display (if any) or just the completion message
    if "_display_variables" in result.variables:
        display_vars = result.variables["_display_variables"]
        if isinstance(display_vars, list):
            print("\nOutput Variables:")
            for var_name in display_vars:
                if var_name in result.variables:
                    print(f"  {var_name}: {result.variables[var_name]}")
    elif result.status == ExecutionStatus.COMPLETED:
        print("\nExecution completed successfully.")


# Module exports
__all__ = [
    "RecipeExecutor",
    "Recipe",
    "RecipeStep",
    "StepType",
    "OutputFormat",
    "ValidationLevel",
    "InteractionMode",
    "ExecutionStatus",
    "StepStatus",
    "RecipeResult",
    "StepResult",
    "ValidationResult",
    "ValidationIssue",
    "ExecutionContext",
    "EventListener",
    "ConsoleEventListener",
]

# Standalone execution
if __name__ == "__main__":
    asyncio.run(main())
