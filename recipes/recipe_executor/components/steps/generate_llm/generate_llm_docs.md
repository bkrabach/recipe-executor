# GenerateWithLLMStep Component Usage

## Importing

```python
from recipe_executor.steps.generate_llm import GenerateWithLLMStep, GenerateLLMConfig
```

## Configuration

The GenerateWithLLMStep is configured with a GenerateLLMConfig:

```python
class GenerateWithLLMConfig(StepConfig):
    """
    Config for GenerateWithLLMStep.

    Fields:
        prompt: The prompt to send to the LLM (templated beforehand).
        model: The model identifier to use (provider/model_name format).
        response_format: The format of the LLM response (text, files, or JSON).
            - text: Plain text response.
            - files: List of files generated by the LLM.
            - JSON: Object based on the provided JSON schema.
        response_key: The name under which to store the LLM response in context.
    """

    prompt: str
    model: str = "openai/gpt-4o"
    response_format: "text" | "files" | jsonschema.Schema = "text"
    response_key: str = "llm_response"
```

## Basic Usage in Recipes

The GenerateWithLLMStep can be used in recipes via the `generate_with_llm` step type:

```json
{
  "steps": [
    {
      "type": "generate_with_llm",
      "prompt": "What is the capital of France?",
      "model": "openai/o3-mini",
      "response_format": "text",
      "response_key": "capital_result"
    }
  ]
}
```

## Template-Based Prompts

The prompt can include template variables from the context:

```json
{
  "steps": [
    {
      "type": "read_files",
      "path": "specs/component_spec.md",
      "content_key": "component_spec_contents"
    },
    {
      "type": "generate_with_llm",
      "prompt": "Based on the following specification, generate python code for a component:\n\n{{component_spec_contents}}",
      "model": "{{model|default:'openai/o3-mini'}}",
      "response_format": "files",
      "response_key": "component_code_files"
    }
  ]
}
```

## Dynamic Response Keys

The response key can be templated to create dynamic storage locations:

```json
{
  "steps": [
    {
      "type": "generate",
      "prompt": "Generate a JSON object with user details.",
      "model": "{{model|default:'openai/o3-mini'}}",
      "response_format": {
        "type": "object",
        "properties": {
          "user": {
            "type": "object",
            "properties": {
              "name": { "type": "string" },
              "age": { "type": "integer" }
            },
            "required": ["name", "age"]
          }
        }
      },
      "response_key": "user_details_{{name}}"
    }
  ]
}
```

## LLM Response Formats

The LLM can return different formats based on the `response_format` parameter:

- **text**: Returns a plain text response.
- **files**: Returns a list of `FileSpec` objects, this is provided as a convenience due to the common use case of generating files from LLMs.
- **JSON**: Returns a JSON object based on the provided JSON schema. The schema is validated before the LLM call, and if invalid, the step will fail.

### Text Example

Request:

```json
{
  "type": "generate_with_llm",
  "prompt": "What is the capital of France?",
  "model": "openai/o3-mini",
  "response_format": "text",
  "response_key": "capital_result"
}
```

Context after execution:

```json
{
  "capital_result": "The capital of France is Paris."
}
```

### Files Example

Request:

```json
{
  "type": "generate_with_llm",
  "prompt": "Generate Python files for a simple calculator.",
  "model": "openai/o3-mini",
  "response_format": "files",
  "response_key": "calculator_files"
}
```

Context after execution:

```json
{
  "calculator_files": [
    {
      "path": "calculator.py",
      "content": "def add(a, b):\n    return a + b\n\ndef subtract(a, b):\n    return a - b"
    },
    {
      "path": "test_calculator.py",
      "content": "import calculator\n\ndef test_add():\n    assert calculator.add(1, 2) == 3\n\ndef test_subtract():\n    assert calculator.subtract(2, 1) == 1"
    }
  ]
}
```

### JSON Example

Request:

```json
{
  "type": "generate_with_llm",
  "prompt": "Extract the list of users from this document: {{document_content}}.",
  "model": "openai/o3-mini",
  "response_format": {
    "type": "list",
    "items": {
      "type": "object",
      "properties": {
        "name": { "type": "string" },
        "age": { "type": "integer" }
      },
      "required": ["name", "age"]
    }
  },
  "response_key": "user_details"
}
```

Context after execution:

```json
{
  "user_details": [
    {
      "name": "Alice",
      "age": 30
    },
    {
      "name": "Bob",
      "age": 25
    }
  ]
}
```
